{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Machine_translation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM89dDudypYhwOzWTwGD04B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AslanDevbrat/NLP/blob/main/Neural_Machine_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DATASET"
      ],
      "metadata": {
        "id": "Y84cCQxE7K32"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6njpBDl6wjA",
        "outputId": "21f0601a-4be2-4bf0-c43c-3f80ea4b2856"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-19 12:26:52--  http://manythings.org/anki/fra-eng.zip\n",
            "Resolving manythings.org (manythings.org)... 173.254.30.110\n",
            "Connecting to manythings.org (manythings.org)|173.254.30.110|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://www.manythings.org/anki/fra-eng.zip [following]\n",
            "--2022-07-19 12:26:52--  http://www.manythings.org/anki/fra-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Reusing existing connection to manythings.org:80.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6612164 (6.3M) [application/zip]\n",
            "Saving to: ‘fra-eng.zip.1’\n",
            "\n",
            "fra-eng.zip.1       100%[===================>]   6.31M  3.70MB/s    in 1.7s    \n",
            "\n",
            "2022-07-19 12:26:54 (3.70 MB/s) - ‘fra-eng.zip.1’ saved [6612164/6612164]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://manythings.org/anki/fra-eng.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/fra-eng.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DAW02lo7KdO",
        "outputId": "a4639460-0d83-4393-a00f-704c05cb9639"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/fra-eng.zip\n",
            "replace _about.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: _about.txt              \n",
            "  inflating: fra.txt                 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from tensorflow.keras.preprocessing import text_dataset_from_directory\n",
        "from tensorflow.keras.layers import SimpleRNN,LSTM, Dense, Reshape, Embedding,GRU,Bidirectional, Input\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTZtHlCR7gN3",
        "outputId": "e9c3f115-7acf-40a1-ad53-8be2cacff221"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path= \"/content/fra.txt\"\n",
        "NUM_EXAMPLES = 2500\n",
        "text_dataset = tf.data.TextLineDataset(path).take(NUM_EXAMPLES)\n"
      ],
      "metadata": {
        "id": "jVSWI9-S7qwA"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def selector(input_text):\n",
        "  return tf.strings.split(input_text, '\\t')[0:1], 'starttoken' + tf.strings.split(input_text, '\\t')[1:2], tf.strings.split(input_text, '\\t')[1:2]\n",
        "\n",
        "text_dataset = text_dataset.map(selector)\n"
      ],
      "metadata": {
        "id": "aTcPBvEi9B5H"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "for i in text_dataset.take(1):\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6Hjpmws-2MG",
        "outputId": "ed605c9e-9ee5-4635-a83f-ad6a180a6636"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttokenVa !'], dtype=object)>, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Va !'], dtype=object)>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_sentences(input_data):\n",
        "    '''\n",
        "    Input: raw reviews\n",
        "    output: standardized reviews\n",
        "    '''\n",
        "    output=tf.strings.lower(input_data)\n",
        "    outputs=tf.strings.regex_replace(output,\"<[^>]+>\",\"\")\n",
        "    outputs=tf.strings.regex_replace(output,\"<[%s]\"%re.escape(string.punctuation),\" \")\n",
        "    outputs=tf.strings.regex_replace(output,\"  \",\" \")\n",
        "    \n",
        "    return output\n",
        "SEQUENCE_LENGTH = 10\n",
        "vectorize_input_layer = TextVectorization(\n",
        "      standardize = preprocess_sentences,\n",
        "      output_sequence_length = SEQUENCE_LENGTH,\n",
        "\n",
        "      )\n",
        "      \n",
        "vectorize_output_layer = TextVectorization(\n",
        "    standardize = preprocess_sentences,\n",
        "    output_sequence_length = SEQUENCE_LENGTH,\n",
        ")\n",
        "\n",
        "vectorize_pre_output_layer = TextVectorization(\n",
        "    standardize = preprocess_sentences,\n",
        "    output_sequence_length = SEQUENCE_LENGTH,\n",
        ")"
      ],
      "metadata": {
        "id": "wdHTO2CG-5RM"
      },
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = text_dataset.map(lambda x,y, z :x)\n",
        "vectorize_input_layer.adapt(training_data)\n",
        "\n",
        "training_data = text_dataset.map(lambda x, y, z :y)\n",
        "vectorize_pre_output_layer.adapt(training_data)\n",
        "\n",
        "training_data = text_dataset.map(lambda x, y, z :z)\n",
        "vectorize_output_layer.adapt(training_data)\n"
      ],
      "metadata": {
        "id": "kgO8LLQIqKsp"
      },
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_INPUT_SIZE  = len(vectorize_input_layer.get_vocabulary())\n",
        "VOCAB_OUTPUT_SIZE = len(vectorize_output_layer.get_vocabulary())\n",
        "VOCAB_PRE_OUTPUT_SIZE=len(vectorize_pre_output_layer.get_vocabulary())\n",
        "print(VOCAB_OUTPUT_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gatwRB6jqMBz",
        "outputId": "f8c3c6ff-d692-40ad-cbee-6f3d35712a8b"
      },
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1830\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def vectorizer(x, y, z):\n",
        "  return {'in1': tf.squeeze(vectorize_input_layer(x), 0) , 'in2': tf.squeeze(vectorize_pre_output_layer(y),0) }, tf.squeeze(tf.one_hot(vectorize_output_layer(z), depth = VOCAB_OUTPUT_SIZE), 0)\n",
        "\n",
        "dataset = text_dataset.map(vectorizer)"
      ],
      "metadata": {
        "id": "7p9YH6AB_Xva"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in dataset.take(1):\n",
        "\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8vdTBgWdEy9",
        "outputId": "b878ea8c-397f-49c4-e256-5b5e446e584d"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'in1': <tf.Tensor: shape=(10,), dtype=int64, numpy=array([24,  0,  0,  0,  0,  0,  0,  0,  0,  0])>, 'in2': <tf.Tensor: shape=(10,), dtype=int64, numpy=array([37,  2,  0,  0,  0,  0,  0,  0,  0,  0])>}, <tf.Tensor: shape=(10, 1830), dtype=float32, numpy=\n",
            "array([[0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 1., ..., 0., 0., 0.],\n",
            "       [1., 0., 0., ..., 0., 0., 0.],\n",
            "       ...,\n",
            "       [1., 0., 0., ..., 0., 0., 0.],\n",
            "       [1., 0., 0., ..., 0., 0., 0.],\n",
            "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATION_RATIO = 1\n",
        "VALIDATION_BRIDGE = int(VALIDATION_RATIO* NUM_EXAMPLES)\n",
        "dataset = dataset.shuffle(NUM_EXAMPLES)\n",
        "train_dataset = dataset.take(VALIDATION_BRIDGE)\n",
        "validation_dataset = dataset.skip(VALIDATION_BRIDGE)"
      ],
      "metadata": {
        "id": "6vlms85exolP"
      },
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "train_dataset=train_dataset.batch(BATCH_SIZE).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_dataset=validation_dataset.batch(BATCH_SIZE).cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "pVs0j8ILz86-"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODELLING"
      ],
      "metadata": {
        "id": "8AoiWX9Y08yP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQUENCE_LENGTH = 10\n",
        "EMBEDDING_DIM = 8\n",
        "enc_size = 300\n",
        "dec_size = 100\n",
        "\n",
        "\n",
        "enc_input = Input((SEQUENCE_LENGTH,),name = 'in1')\n",
        "dec_input = Input((SEQUENCE_LENGTH,), name = 'in2')\n",
        "\n",
        "x = Embedding(VOCAB_INPUT_SIZE, EMBEDDING_DIM)(enc_input)\n",
        "\n",
        "encoder = LSTM(enc_size, return_sequences= False, return_state = True)\n",
        "_ , h, c = encoder(x)\n",
        "\n",
        "x = Embedding(VOCAB_PRE_OUTPUT_SIZE, EMBEDDING_DIM)(dec_input)\n",
        "\n",
        "decoder = LSTM(dec_size, return_sequences=True, return_state = True)\n",
        "h = Dense(dec_size)(h)\n",
        "c = Dense(dec_size)(c)\n",
        "\n",
        "x, h, c = decoder(x, [h, c])\n",
        "x = Dense(VOCAB_OUTPUT_SIZE, activation = \"softmax\")(x)\n",
        "\n",
        "model = tf.keras.Model([enc_input, dec_input], x)\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-EQUhEv5m-D",
        "outputId": "7a97274d-58c0-472f-8725-9d8834dcc0eb"
      },
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_20\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " in1 (InputLayer)               [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding_54 (Embedding)       (None, 10, 8)        6768        ['in1[0][0]']                    \n",
            "                                                                                                  \n",
            " in2 (InputLayer)               [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " lstm_49 (LSTM)                 [(None, 300),        370800      ['embedding_54[0][0]']           \n",
            "                                 (None, 300),                                                     \n",
            "                                 (None, 300)]                                                     \n",
            "                                                                                                  \n",
            " embedding_55 (Embedding)       (None, 10, 8)        15336       ['in2[0][0]']                    \n",
            "                                                                                                  \n",
            " dense_63 (Dense)               (None, 100)          30100       ['lstm_49[0][1]']                \n",
            "                                                                                                  \n",
            " dense_64 (Dense)               (None, 100)          30100       ['lstm_49[0][2]']                \n",
            "                                                                                                  \n",
            " lstm_50 (LSTM)                 [(None, 10, 100),    43600       ['embedding_55[0][0]',           \n",
            "                                 (None, 100),                     'dense_63[0][0]',               \n",
            "                                 (None, 100)]                     'dense_64[0][0]']               \n",
            "                                                                                                  \n",
            " dense_65 (Dense)               (None, 10, 1830)     184830      ['lstm_50[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 681,534\n",
            "Trainable params: 681,534\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "US1jywBscEyI"
      },
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 1e-3\n",
        "EPOCH = 100\n",
        "\n",
        "model.compile(\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(from_logits = True),\n",
        "    optimizer = tf.keras.optimizers.Adam(lr = LR,),\n",
        "    metrics = [\"accuracy\"],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2NnzfWZUp7Z",
        "outputId": "e380aa79-5451-4c3a-f297-04109b2225bb"
      },
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DEvehnGDiN1u"
      },
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in train_dataset.take(1):\n",
        "  print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bs2SkBXiRIs",
        "outputId": "352deebf-1565-4283-a2b6-3c5c63fb1dd9"
      },
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'in1': <tf.Tensor: shape=(64, 10), dtype=int64, numpy=\n",
            "array([[  6, 362,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  2,  74,  60,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [ 14,  37,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [475, 142,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  2,  58, 139,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [ 15,  40,  24,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [416,   4,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  6,  31,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [238,  19,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [ 58, 130,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  2,  72,   4,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  2,  76,   4,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  5, 103,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  8, 134,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [189,  75,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [409,  12,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [ 14, 222,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  2, 518, 243,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  3, 307,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  8,  77,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [193,  78,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [ 16,   4,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [656,  47,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [127,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [276,   4,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [ 23,  86,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [235,   4,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  6,  92,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  9,  60,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  3,  43,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  3, 312,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  3,  33, 800,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  2, 259,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [289,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [199,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [118, 390,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  6, 590,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  8, 134,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [ 25, 174,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [142,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [ 97,  32,  78,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  3, 451,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  7, 176,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  5,  31,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  6, 471,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [570, 202,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  7,  37,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [ 97,  32, 253,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [138,   4,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  7,  50,  84,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  2,  58, 652,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  8, 143, 236,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [ 44,  31,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [166, 579,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  2,  41, 212,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  2, 101,  24,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [ 27,   2, 510,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [ 89,  13,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [175,  13,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [ 70, 115,  28,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [129,  51,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [ 16, 478,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [ 79, 201,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [ 81,  54,   0,   0,   0,   0,   0,   0,   0,   0]])>, 'in2': <tf.Tensor: shape=(64, 10), dtype=int64, numpy=\n",
            "array([[   6, 1641,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [   3,    4, 1659,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [ 964,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [ 123,  151,    5,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [   3,    4, 1750,   66,    0,    0,    0,    0,    0,    0],\n",
            "       [  54,  221,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [1180,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [   6,   57,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [   3,   43,  329,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [1218,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [  25,   12,  339,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [   3,   36,  174,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [  37,   43,  240, 1667,    0,    0,    0,    0,    0,    0],\n",
            "       [  16,  574,    2,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [  55,   41,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [1248,   14,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [  24,  570,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [1095,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [   3,  353,  670,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [  16,  707,    2,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [ 461,   11, 1863,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [ 465,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [1148,    2,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [ 202,    2,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [1020,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [1139,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [ 907,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [   6,  551,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [   8,   19,  109,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [   3,    4, 1373,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [   3,    4, 1668,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [   3,    4, 1675,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [   7,  228,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [  33,  187, 1342,    2,    0,    0,    0,    0,    0,    0],\n",
            "       [ 936,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [ 204,   10,  607,  566,    0,    0,    0,    0,    0,    0],\n",
            "       [   6, 1684,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [  28,  218,    2,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [1112,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [ 123,  151,    5,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [ 153, 1577,    5,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [   3,    4, 1392,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [ 894,  130,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [ 145,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [   6,   58,  585,  193,   27,    0,    0,    0,    0,    0],\n",
            "       [ 199,  596, 1825,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [ 118,  177,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [  63,  255,   68,    5,    0,    0,    0,    0,    0,    0],\n",
            "       [1134,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [  37,   43, 1782,    2,    0,    0,    0,    0,    0,    0],\n",
            "       [  53,  230,  831,  243,    0,    0,    0,    0,    0,    0],\n",
            "       [  16,   10,  355,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [  75,  108,   57,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [ 880,    2,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [  81,  147,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [  13,   12,  132,  169,    0,    0,    0,    0,    0,    0],\n",
            "       [  52, 1707,    5,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [ 905,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [1038,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [ 947,    2,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [  21, 1897,  641,    2,    0,    0,    0,    0,    0,    0],\n",
            "       [  50,  371,  603,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [1163,    2,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "       [ 474,    0,    0,    0,    0,    0,    0,    0,    0,    0]])>}, <tf.Tensor: shape=(64, 10, 1830), dtype=float32, numpy=\n",
            "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [1., 0., 0., ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [1., 0., 0., ..., 0., 0., 0.],\n",
            "        [1., 0., 0., ..., 0., 0., 0.],\n",
            "        [1., 0., 0., ..., 0., 0., 0.]],\n",
            "\n",
            "       [[0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [1., 0., 0., ..., 0., 0., 0.],\n",
            "        [1., 0., 0., ..., 0., 0., 0.],\n",
            "        [1., 0., 0., ..., 0., 0., 0.]],\n",
            "\n",
            "       [[0., 0., 0., ..., 0., 0., 0.],\n",
            "        [1., 0., 0., ..., 0., 0., 0.],\n",
            "        [1., 0., 0., ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [1., 0., 0., ..., 0., 0., 0.],\n",
            "        [1., 0., 0., ..., 0., 0., 0.],\n",
            "        [1., 0., 0., ..., 0., 0., 0.]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [1., 0., 0., ..., 0., 0., 0.],\n",
            "        [1., 0., 0., ..., 0., 0., 0.],\n",
            "        [1., 0., 0., ..., 0., 0., 0.]],\n",
            "\n",
            "       [[0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 1., ..., 0., 0., 0.],\n",
            "        [1., 0., 0., ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [1., 0., 0., ..., 0., 0., 0.],\n",
            "        [1., 0., 0., ..., 0., 0., 0.],\n",
            "        [1., 0., 0., ..., 0., 0., 0.]],\n",
            "\n",
            "       [[0., 0., 0., ..., 0., 0., 0.],\n",
            "        [1., 0., 0., ..., 0., 0., 0.],\n",
            "        [1., 0., 0., ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [1., 0., 0., ..., 0., 0., 0.],\n",
            "        [1., 0., 0., ..., 0., 0., 0.],\n",
            "        [1., 0., 0., ..., 0., 0., 0.]]], dtype=float32)>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_filepath  = \"seq2seq.hdf5\"\n",
        "\n",
        "#checkpoint_filepath=\"imdb/basic_rnn.hdf5\"\n",
        "callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "   filepath=checkpoint_filepath,### WHERE BEST WEIGHTS ARE STORED\n",
        "    save_weights_only=True,\n",
        "   monitor=\"loss\",\n",
        "   mode='min',\n",
        "    save_best_only=True)\n",
        "#Train model on dataset\n",
        "history=model.fit(train_dataset,verbose=1,epochs=EPOCH,callbacks=[callback])#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgGPngRZY5We",
        "outputId": "c25f1989-21a6-4ddc-afbc-4ce36939534b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " vectorize_output_layer.get_vocabulary()"
      ],
      "metadata": {
        "id": "EgxNi6emfEK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " "
      ],
      "metadata": {
        "id": "tGNTicKOfSWn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}