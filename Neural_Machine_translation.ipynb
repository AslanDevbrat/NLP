{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Machine_translation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNVbFXP8GKuHeTfPFtkRUqS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AslanDevbrat/NLP/blob/main/Neural_Machine_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DATASET"
      ],
      "metadata": {
        "id": "Y84cCQxE7K32"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6njpBDl6wjA",
        "outputId": "9bbfbdb0-e762-4886-f4cb-568951c21e56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-20 11:01:03--  http://manythings.org/anki/fra-eng.zip\n",
            "Resolving manythings.org (manythings.org)... 173.254.30.110\n",
            "Connecting to manythings.org (manythings.org)|173.254.30.110|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://www.manythings.org/anki/fra-eng.zip [following]\n",
            "--2022-07-20 11:01:03--  http://www.manythings.org/anki/fra-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Reusing existing connection to manythings.org:80.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6612164 (6.3M) [application/zip]\n",
            "Saving to: ‘fra-eng.zip’\n",
            "\n",
            "fra-eng.zip         100%[===================>]   6.31M  20.2MB/s    in 0.3s    \n",
            "\n",
            "2022-07-20 11:01:03 (20.2 MB/s) - ‘fra-eng.zip’ saved [6612164/6612164]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://manythings.org/anki/fra-eng.zip\n",
        "!unzip /content/fra-eng.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DAW02lo7KdO",
        "outputId": "bbba1bf2-acd2-4d2a-b6dc-d77e24990e61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/fra-eng.zip\n",
            "  inflating: _about.txt              \n",
            "  inflating: fra.txt                 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from tensorflow.keras.preprocessing import text_dataset_from_directory\n",
        "from tensorflow.keras.layers import SimpleRNN,LSTM, Dense, Reshape, Embedding,GRU,Bidirectional, Input\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTZtHlCR7gN3",
        "outputId": "bdb44e27-9cc4-432d-d006-208a7676df92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path= \"/content/fra.txt\"\n",
        "NUM_EXAMPLES = 250\n",
        "text_dataset = tf.data.TextLineDataset(path).take(NUM_EXAMPLES)\n"
      ],
      "metadata": {
        "id": "jVSWI9-S7qwA"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def selector(input_text):\n",
        "  return tf.strings.split(input_text, '\\t')[0:1], 'starttoken ' + tf.strings.split(input_text, '\\t')[1:2], tf.strings.split(input_text, '\\t')[1:2]\n",
        "\n",
        "text_dataset = text_dataset.map(selector)\n"
      ],
      "metadata": {
        "id": "aTcPBvEi9B5H"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "for i in text_dataset.take(1):\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6Hjpmws-2MG",
        "outputId": "f48249cd-f175-41cb-af3b-bb675bbc0f05"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Va !'], dtype=object)>, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Va !'], dtype=object)>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_sentences(input_data):\n",
        "    '''\n",
        "    Task: Preprocess sentences or standardize the sentences\n",
        "    Input: raw reviews\n",
        "    output: standardized reviews\n",
        "    '''\n",
        "    output=tf.strings.lower(input_data)\n",
        "    outputs=tf.strings.regex_replace(output,\"<[^>]+>\",\"\")\n",
        "    outputs=tf.strings.regex_replace(output,\"<[%s]\"%re.escape(string.punctuation),\" \")\n",
        "    outputs=tf.strings.regex_replace(output,\"  \",\" \")\n",
        "    \n",
        "    return output\n",
        "SEQUENCE_LENGTH = 10\n",
        "vectorize_input_layer = TextVectorization(\n",
        "      standardize = preprocess_sentences,\n",
        "      output_sequence_length = SEQUENCE_LENGTH,\n",
        "\n",
        "      )\n",
        "      \n",
        "vectorize_output_layer = TextVectorization(\n",
        "    standardize = preprocess_sentences,\n",
        "    output_sequence_length = SEQUENCE_LENGTH,\n",
        ")\n",
        "\n",
        "vectorize_pre_output_layer = TextVectorization(\n",
        "    standardize = preprocess_sentences,\n",
        "    output_sequence_length = SEQUENCE_LENGTH,\n",
        ")"
      ],
      "metadata": {
        "id": "wdHTO2CG-5RM"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = text_dataset.map(lambda x,y, z :x)\n",
        "vectorize_input_layer.adapt(training_data)\n",
        "\n",
        "training_data = text_dataset.map(lambda x, y, z :y)\n",
        "vectorize_pre_output_layer.adapt(training_data)\n",
        "\n",
        "training_data = text_dataset.map(lambda x, y, z :z)\n",
        "vectorize_output_layer.adapt(training_data)\n"
      ],
      "metadata": {
        "id": "kgO8LLQIqKsp"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_INPUT_SIZE  = len(vectorize_input_layer.get_vocabulary())\n",
        "VOCAB_OUTPUT_SIZE = len(vectorize_output_layer.get_vocabulary())\n",
        "VOCAB_PRE_OUTPUT_SIZE=len(vectorize_pre_output_layer.get_vocabulary())\n",
        "print(VOCAB_OUTPUT_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gatwRB6jqMBz",
        "outputId": "f78373cb-fcd3-4b52-95ed-5aa953ff7d21"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "270\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_pre_output_layer.get_vocabulary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goejfGqS1q5j",
        "outputId": "31368118-5d9b-4178-8368-e276c93a27d8"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " 'starttoken',\n",
              " '!',\n",
              " 'je',\n",
              " 'soyez',\n",
              " 'sois',\n",
              " \"j'ai\",\n",
              " 'le',\n",
              " '?',\n",
              " 'vos',\n",
              " 'de',\n",
              " 'À',\n",
              " 'tomber',\n",
              " 'suis',\n",
              " 'nous',\n",
              " 'camp',\n",
              " \"c'est\",\n",
              " 'à',\n",
              " 'Ça',\n",
              " 'va',\n",
              " 'question',\n",
              " 'pas',\n",
              " 'merci',\n",
              " 'maintenant.',\n",
              " 'hors',\n",
              " 'fiche',\n",
              " 'en',\n",
              " 'dégage\\u202f!',\n",
              " 'du',\n",
              " 'casse-toi.',\n",
              " 'équitable',\n",
              " 'vraiment',\n",
              " 'viens\\xa0!',\n",
              " 'venez\\u202f!',\n",
              " 'tom.',\n",
              " 'te',\n",
              " 'sortez\\u202f!',\n",
              " 'sors.',\n",
              " 'saute.',\n",
              " 'santé',\n",
              " 'salut',\n",
              " 'prenez',\n",
              " 'pars',\n",
              " 'oust',\n",
              " 'on',\n",
              " 'là.',\n",
              " 'j’ai',\n",
              " 'juste',\n",
              " 'jambes',\n",
              " 'gentille',\n",
              " 'gentil',\n",
              " 'gagné.',\n",
              " 'fuyons',\n",
              " 'fuyez',\n",
              " 'filez',\n",
              " 'file',\n",
              " 'essaye.',\n",
              " 'décampe',\n",
              " 'disparais\\u202f!',\n",
              " 'disparais',\n",
              " 'dans',\n",
              " \"d'ici.\",\n",
              " 'cous',\n",
              " 'cours\\u202f!',\n",
              " 'cours',\n",
              " 'courez\\u202f!',\n",
              " 'camp.',\n",
              " 'calme',\n",
              " 'bras',\n",
              " 'bouge',\n",
              " 'attends',\n",
              " 'attendez.',\n",
              " 'attendez',\n",
              " 'ah',\n",
              " 'équitables',\n",
              " 'Écoutez',\n",
              " 'y',\n",
              " 'waouh\\xa0!',\n",
              " 'wah\\xa0!',\n",
              " 'vraiment\\u202f?',\n",
              " 'vrai,',\n",
              " 'vrai',\n",
              " 'votre',\n",
              " 'vers',\n",
              " 'va\\xa0!',\n",
              " 'vas-y',\n",
              " 'vais',\n",
              " 'va.',\n",
              " 'va-t’en\\xa0!',\n",
              " 'va,',\n",
              " 'tricote.',\n",
              " 'tranquille.',\n",
              " 'tombée.',\n",
              " 'tombé.',\n",
              " 'tire-toi',\n",
              " 'tes',\n",
              " 'terre\\xa0!',\n",
              " 'tchin-tchin',\n",
              " \"t'as\",\n",
              " 'suffit\\u202f!',\n",
              " 'stop\\u202f!',\n",
              " 'souris',\n",
              " 'souriez\\u202f!',\n",
              " 'souriez\\u2009!',\n",
              " 'sortez.',\n",
              " 'sortez',\n",
              " 'sors',\n",
              " 'sincère.',\n",
              " 'serrez-moi',\n",
              " 'serre-moi',\n",
              " 'sensass',\n",
              " 'secouez-vous',\n",
              " 'secoue-toi',\n",
              " 'sans',\n",
              " 'salut.',\n",
              " 'sais.',\n",
              " 'remercie.',\n",
              " 'relaxe,',\n",
              " 'relaxe',\n",
              " 'raoul\\u202f!',\n",
              " 'qui',\n",
              " 'question\\u202f!',\n",
              " 'poursuivez.',\n",
              " 'poursuis.',\n",
              " 'pour',\n",
              " 'possible\\u202f!',\n",
              " 'pliez-le.',\n",
              " 'pliez-la.',\n",
              " 'plie-le.',\n",
              " 'plie-la.',\n",
              " 'pigé\\u202f?',\n",
              " 'pigé',\n",
              " 'perdu.',\n",
              " 'payé.',\n",
              " 'payais.',\n",
              " 'payai.',\n",
              " 'partie.',\n",
              " 'parti.',\n",
              " 'pardon',\n",
              " 'oh',\n",
              " 'non',\n",
              " \"n'en\",\n",
              " 'montez.',\n",
              " 'monte.',\n",
              " 'merci.',\n",
              " 'menti.',\n",
              " 'max\\u202f!',\n",
              " 'marche.',\n",
              " 'manière',\n",
              " 'mangez-le.',\n",
              " 'mange-le.',\n",
              " 'lève-toi.',\n",
              " 'lève-toi',\n",
              " 'laissez-le',\n",
              " 'laissez',\n",
              " 'laisse-le',\n",
              " 'laisse',\n",
              " 'la',\n",
              " \"l'extérieur\",\n",
              " \"l'emportâmes.\",\n",
              " \"l'avons\",\n",
              " \"l'attaque\",\n",
              " \"l'aide\\u202f!\",\n",
              " \"l'ai\",\n",
              " 'justes',\n",
              " \"j'essaye.\",\n",
              " \"j'arrête.\",\n",
              " 'impossible\\u202f!',\n",
              " 'il',\n",
              " 'honnêtes.',\n",
              " 'honnête.',\n",
              " 'gentils',\n",
              " 'gentilles',\n",
              " 'gentil.',\n",
              " 'gagné',\n",
              " 'gagnâmes.',\n",
              " 'fui.',\n",
              " 'foutre',\n",
              " 'foutez',\n",
              " 'fous',\n",
              " 'fichez',\n",
              " 'feu',\n",
              " 'façons\\u202f!',\n",
              " 'fantastique\\u202f!',\n",
              " 'faire',\n",
              " 'exclu',\n",
              " 'est',\n",
              " 'essayez.',\n",
              " 'essaie.',\n",
              " 'entrez\\u202f!',\n",
              " 'entrez',\n",
              " 'entre.',\n",
              " 'entre',\n",
              " 'enterrez-le.',\n",
              " 'enterrez-la.',\n",
              " 'enterre-le.',\n",
              " 'enterre-la.',\n",
              " 'emporté.',\n",
              " 'emporté',\n",
              " 'détendu',\n",
              " 'détends-toi\\u202f!',\n",
              " 'détends-toi.',\n",
              " 'détends-toi',\n",
              " 'détendez-vous\\u202f!',\n",
              " 'déguerpissez.',\n",
              " 'dégagez',\n",
              " 'dégage.',\n",
              " 'dégage',\n",
              " 'décampez',\n",
              " 'dis',\n",
              " 'demande-lui.',\n",
              " 'demande',\n",
              " 'debout.',\n",
              " 'cool,',\n",
              " 'continuez.',\n",
              " 'compris\\u202f?',\n",
              " 'compris',\n",
              " 'comprends.',\n",
              " 'commencez.',\n",
              " 'commence.',\n",
              " 'chercher',\n",
              " 'casse-toi',\n",
              " 'cas.',\n",
              " 'capté\\u202f?',\n",
              " 'caméra.',\n",
              " 'calme\\u202f!',\n",
              " 'calmez-vous',\n",
              " 'calmes',\n",
              " 'calme.',\n",
              " 'calme-toi.',\n",
              " 'cachez-vous.',\n",
              " 'cache-toi.',\n",
              " 'brûlez-le.',\n",
              " 'brûlez-la.',\n",
              " 'brûle-le.',\n",
              " 'brûle-la.',\n",
              " 'bonjour',\n",
              " 'bon',\n",
              " 'bien.',\n",
              " 'balai',\n",
              " 'baissez-vous\\xa0!',\n",
              " 'baisse-toi\\xa0!',\n",
              " 'avons',\n",
              " 'avant\\u202f!',\n",
              " 'aucune',\n",
              " 'aucun',\n",
              " 'au',\n",
              " 'attends.',\n",
              " 'attaquez',\n",
              " 'attaque',\n",
              " 'arrêté.',\n",
              " 'arrête-toi',\n",
              " 'appelle-nous',\n",
              " 'appelle-moi',\n",
              " 'appelez-nous',\n",
              " 'appelez-moi\\xa0!',\n",
              " 'ans.',\n",
              " 'alors\\u202f!',\n",
              " 'allons',\n",
              " 'allez\\u202f!',\n",
              " 'allez-y',\n",
              " 'allez,',\n",
              " 'allez',\n",
              " 'aha.',\n",
              " 'aha',\n",
              " 'achète-le',\n",
              " 'achète-la',\n",
              " 'achetez-le',\n",
              " 'achetez-la',\n",
              " '19']"
            ]
          },
          "metadata": {},
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def vectorizer(x, y, z):\n",
        "  return {'in1': tf.squeeze(vectorize_input_layer(x), 0) , 'in2': tf.squeeze(vectorize_pre_output_layer(y),0) }, tf.squeeze(tf.one_hot(vectorize_output_layer(z), depth = VOCAB_OUTPUT_SIZE), 0)\n",
        "\n",
        "dataset = text_dataset.map(vectorizer)"
      ],
      "metadata": {
        "id": "7p9YH6AB_Xva"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in dataset.take(1):\n",
        "\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8vdTBgWdEy9",
        "outputId": "3613152e-9113-468c-ef82-409501f362c8"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'in1': <tf.Tensor: shape=(10,), dtype=int64, numpy=array([46,  0,  0,  0,  0,  0,  0,  0,  0,  0])>, 'in2': <tf.Tensor: shape=(10,), dtype=int64, numpy=array([ 2, 20,  3,  0,  0,  0,  0,  0,  0,  0])>}, <tf.Tensor: shape=(10, 270), dtype=float32, numpy=\n",
            "array([[0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 1., ..., 0., 0., 0.],\n",
            "       [1., 0., 0., ..., 0., 0., 0.],\n",
            "       ...,\n",
            "       [1., 0., 0., ..., 0., 0., 0.],\n",
            "       [1., 0., 0., ..., 0., 0., 0.],\n",
            "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATION_RATIO = 0.8\n",
        "VALIDATION_BRIDGE = int(VALIDATION_RATIO* NUM_EXAMPLES)\n",
        "dataset = dataset.shuffle(NUM_EXAMPLES)\n",
        "train_dataset = dataset.take(VALIDATION_BRIDGE)\n",
        "validation_dataset = dataset.skip(VALIDATION_BRIDGE)"
      ],
      "metadata": {
        "id": "6vlms85exolP"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "train_dataset=train_dataset.batch(BATCH_SIZE).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_dataset=validation_dataset.batch(BATCH_SIZE).cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "pVs0j8ILz86-"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODELLING"
      ],
      "metadata": {
        "id": "8AoiWX9Y08yP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQUENCE_LENGTH = 10\n",
        "EMBEDDING_DIM = 16\n",
        "enc_size = 300\n",
        "dec_size = 100\n",
        "\n",
        "\n",
        "enc_input = Input((SEQUENCE_LENGTH,),name = 'in1')\n",
        "dec_input = Input((SEQUENCE_LENGTH,), name = 'in2')\n",
        "\n",
        "x = Embedding(VOCAB_INPUT_SIZE, EMBEDDING_DIM)(enc_input)\n",
        "\n",
        "encoder = LSTM(enc_size, return_sequences= False, return_state = True)\n",
        "_ , h, c = encoder(x)\n",
        "\n",
        "x = Embedding(VOCAB_PRE_OUTPUT_SIZE, EMBEDDING_DIM)(dec_input)\n",
        "\n",
        "decoder = LSTM(dec_size, return_sequences=True, return_state = True)\n",
        "h = Dense(dec_size)(h)\n",
        "c = Dense(dec_size)(c)\n",
        "\n",
        "x, h, c = decoder(x, [h, c])\n",
        "x = Dense(VOCAB_OUTPUT_SIZE, activation = \"softmax\")(x)\n",
        "\n",
        "model = tf.keras.Model([enc_input, dec_input], x)\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-EQUhEv5m-D",
        "outputId": "6c03201f-9719-4acd-a8b0-67c837d38924"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " in1 (InputLayer)               [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding_14 (Embedding)       (None, 10, 16)       1392        ['in1[0][0]']                    \n",
            "                                                                                                  \n",
            " in2 (InputLayer)               [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " lstm_14 (LSTM)                 [(None, 300),        380400      ['embedding_14[0][0]']           \n",
            "                                 (None, 300),                                                     \n",
            "                                 (None, 300)]                                                     \n",
            "                                                                                                  \n",
            " embedding_15 (Embedding)       (None, 10, 16)       4336        ['in2[0][0]']                    \n",
            "                                                                                                  \n",
            " dense_21 (Dense)               (None, 100)          30100       ['lstm_14[0][1]']                \n",
            "                                                                                                  \n",
            " dense_22 (Dense)               (None, 100)          30100       ['lstm_14[0][2]']                \n",
            "                                                                                                  \n",
            " lstm_15 (LSTM)                 [(None, 10, 100),    46800       ['embedding_15[0][0]',           \n",
            "                                 (None, 100),                     'dense_21[0][0]',               \n",
            "                                 (None, 100)]                     'dense_22[0][0]']               \n",
            "                                                                                                  \n",
            " dense_23 (Dense)               (None, 10, 270)      27270       ['lstm_15[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 520,398\n",
            "Trainable params: 520,398\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Bleu(tf.keras.metrics.Metric):\n",
        "\n",
        "  def __init__(self, name = 'bleu_score'):\n",
        "    super(Bleu, self).__init__()\n",
        "    self.add = 0\n",
        "    self.total = 0\n",
        "  \n",
        "  def update_state(self, y_true, y_pred, sample_weight = None):\n",
        "    #\n",
        "    y_true = tf.argmax(y_true, -1)\n",
        "    y_pred = tf.argmax(y_pred, -1)\n",
        "\n",
        "    for i, j in zip(y_pred, y_true):\n",
        "      tf.autograph.experimental.set_loop_options()\n",
        "      self.total += tf.math.count_nonzero(i)\n",
        "\n",
        "      for word in i:\n",
        "        if (word == 0):\n",
        "          break\n",
        "        for q in range(len(j)):\n",
        "          if word == j[q]:\n",
        "            self.add += 1\n",
        "            j = tf.boolean_mask(j, [False if  y==q else True for y in range(len(j)) ])\n",
        "            break\n",
        "          \n",
        "  def result(self):\n",
        "    return self.add/self.total\n",
        "  \n",
        "  def penalty(self):\n",
        "    if self.add > self.total:\n",
        "      return 1\n",
        "    else:\n",
        "      return tf.math.exp(1- (self.total/self.add))"
      ],
      "metadata": {
        "id": "US1jywBscEyI"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 1e-3\n",
        "EPOCH = 100\n",
        "\n",
        "model.compile(\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(from_logits = True),\n",
        "    optimizer = tf.keras.optimizers.Adam(lr = LR,),\n",
        "    metrics = [Bleu()],\n",
        "    run_eagerly = True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2NnzfWZUp7Z",
        "outputId": "9fba3b79-5a73-4de4-d63b-4643227d2a37"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DEvehnGDiN1u"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_filepath  = \"seq2seq.hdf5\"\n",
        "\n",
        "#checkpoint_filepath=\"imdb/basic_rnn.hdf5\"\n",
        "callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "   filepath=checkpoint_filepath,### WHERE BEST WEIGHTS ARE STORED\n",
        "    save_weights_only=True,\n",
        "   monitor=\"loss\",\n",
        "   mode='min',\n",
        "    save_best_only=True)\n",
        "#Train model on dataset\n",
        "history=model.fit(train_dataset, validation_data = val_dataset, verbose=1,epochs=EPOCH,callbacks=[callback])#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wgGPngRZY5We",
        "outputId": "b2eadaf5-d814-4564-b5d9-bf1a23355d4c"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <bound method Bleu.update_state of <__main__.Bleu object at 0x7f0b2380d610>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: not enough values to unpack (expected 2, got 0)\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <bound method Bleu.update_state of <__main__.Bleu object at 0x7f0b2380d610>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: not enough values to unpack (expected 2, got 0)\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <bound method Bleu.update_state of <__main__.Bleu object at 0x7f0b2380d610>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: not enough values to unpack (expected 2, got 0)\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "4/4 [==============================] - 7s 624ms/step - loss: 1.1217 - bleu_21: 0.2850 - val_loss: 1.1382 - val_bleu_21: 0.3000\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 1s 360ms/step - loss: 1.0992 - bleu_21: 0.3492 - val_loss: 1.1275 - val_bleu_21: 0.3492\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 1s 287ms/step - loss: 1.0851 - bleu_21: 0.3492 - val_loss: 1.1230 - val_bleu_21: 0.3492\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 1s 289ms/step - loss: 1.0765 - bleu_21: 0.3492 - val_loss: 1.1202 - val_bleu_21: 0.3492\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 1s 295ms/step - loss: 1.0699 - bleu_21: 0.3492 - val_loss: 1.1172 - val_bleu_21: 0.3492\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 1s 297ms/step - loss: 1.0632 - bleu_21: 0.3492 - val_loss: 1.1132 - val_bleu_21: 0.3492\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 1s 295ms/step - loss: 1.0566 - bleu_21: 0.3492 - val_loss: 1.1104 - val_bleu_21: 0.3492\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 1s 290ms/step - loss: 1.0502 - bleu_21: 0.3492 - val_loss: 1.1087 - val_bleu_21: 0.3492\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 2s 452ms/step - loss: 1.0438 - bleu_21: 0.2685 - val_loss: 1.1064 - val_bleu_21: 0.2465\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 2s 453ms/step - loss: 1.0376 - bleu_21: 0.1924 - val_loss: 1.1035 - val_bleu_21: 0.1818\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 2s 433ms/step - loss: 1.0310 - bleu_21: 0.1538 - val_loss: 1.1002 - val_bleu_21: 0.1476\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 2s 441ms/step - loss: 1.0243 - bleu_21: 0.1305 - val_loss: 1.0973 - val_bleu_21: 0.1263\n",
            "Epoch 13/100\n",
            "2/4 [==============>...............] - ETA: 0s - loss: 1.0028 - bleu_21: 0.1186"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-208-0979034df7e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     save_best_only=True)\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#Train model on dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m   1019\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;34m\"\"\"Runs a training execution with a single step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1008\u001b[0m             run_step, jit_compile=True, experimental_relax_shapes=True)\n\u001b[1;32m   1009\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m   1012\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1311\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1312\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2886\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2887\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2888\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2890\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3687\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3688\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3689\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3691\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1000\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1001\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_target_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m     \u001b[0;31m# Run backwards pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[1;32m    529\u001b[0m     \"\"\"\n\u001b[1;32m    530\u001b[0m     grads_and_vars = self._compute_gradients(\n\u001b[0;32m--> 531\u001b[0;31m         loss, var_list=var_list, grad_loss=grad_loss, tape=tape)\n\u001b[0m\u001b[1;32m    532\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_compute_gradients\u001b[0;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/gradients\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m       \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     self._assert_valid_dtypes([\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_get_gradients\u001b[0;34m(self, tape, loss, var_list, grad_loss)\u001b[0m\n\u001b[1;32m    462\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0;34m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1087\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     71\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    154\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_grad.py\u001b[0m in \u001b[0;36m_SplitGrad\u001b[0;34m(op, *grads)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegisterGradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Split\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_SplitGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1777\u001b[0m           dtype=dtypes.int32).get_shape().assert_has_rank(0)\n\u001b[1;32m   1778\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1779\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1252\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m-> 1254\u001b[0;31m         _ctx, \"ConcatV2\", name, values, axis)\n\u001b[0m\u001b[1;32m   1255\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " vectorize_output_layer.get_vocabulary()"
      ],
      "metadata": {
        "id": "EgxNi6emfEK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "f0hTGZw4tyNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = tf.data.Dataset.from_tensor_slices([['i will try']])\n",
        "init_test_data = tf.data.Dataset.from_tensor_slices([[\"starttoken je soyez\"]])\n",
        "\n",
        "input_test_data = test_data.map(vectorize_input_layer)\n",
        "pre_output_test_data = init_test_data.map(vectorize_pre_output_layer)\n",
        "for i in input_test_data.take(1):\n",
        "  print(i)\n",
        "  in_1 = i\n",
        "\n",
        "for i in pre_output_test_data.take(1):\n",
        "  print(i)\n",
        "  in_2 =i"
      ],
      "metadata": {
        "id": "tGNTicKOfSWn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6fb2cd6-1f3f-4917-cc17-55bc4d52065b"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[ 4  1 38  0  0  0  0  0  0  0]], shape=(1, 10), dtype=int64)\n",
            "tf.Tensor([[2 4 5 0 0 0 0 0 0 0]], shape=(1, 10), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_output(in_1, in_2):\n",
        "  return tf.argmax(model.predict([in_1, in_2]), -1)\n",
        "output = get_output(in_1, in_2)\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZifxHVY0eQH",
        "outputId": "a4af7349-c1d4-4329-dbe5-1c2e128d2ee5"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 10), dtype=int64, numpy=array([[4, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(SEQUENCE_LENGTH):\n",
        "  print(vectorize_output_layer.get_vocabulary()[output[0][i]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpLurYB3nSDY",
        "outputId": "2243efd0-ce4c-4c5a-9a58-497f4bc4d3e4"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "soyez\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_pre_output_layer.get_vocabulary()[output[0][0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2FBe1Bu_4PtI",
        "outputId": "d50da7b7-5398-4f95-c77b-b1225de0d4d2"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'je'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_pre_output_layer.get_vocabulary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkL0_sIAyP63",
        "outputId": "35599fa8-fb61-4dbe-f22d-f9b3b2fc435e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " 'starttoken',\n",
              " '!',\n",
              " 'je',\n",
              " 'suis',\n",
              " \"c'est\",\n",
              " '?',\n",
              " \"j'ai\",\n",
              " 'tom',\n",
              " 'est',\n",
              " 'à',\n",
              " 'de',\n",
              " 'le',\n",
              " 'me',\n",
              " 'il',\n",
              " 'tom.',\n",
              " 'nous',\n",
              " 'en',\n",
              " 'soyez',\n",
              " 'la',\n",
              " 'ne',\n",
              " 'a',\n",
              " 'vous',\n",
              " 'restez',\n",
              " 'reste',\n",
              " 'pas',\n",
              " 'un',\n",
              " 'Ça',\n",
              " 'qui',\n",
              " 'ça.',\n",
              " 'sois',\n",
              " 'pas.',\n",
              " 'va',\n",
              " 'est-ce',\n",
              " 'du',\n",
              " 'les',\n",
              " 'au',\n",
              " 'À',\n",
              " 'j’ai',\n",
              " 'fais',\n",
              " 'ça',\n",
              " \"l'ai\",\n",
              " \"j'en\",\n",
              " 'te',\n",
              " 'ici.',\n",
              " 'elle',\n",
              " 'calme.',\n",
              " 'ai',\n",
              " 'prends',\n",
              " 'bien.',\n",
              " 'bien',\n",
              " 'plus',\n",
              " 'fait',\n",
              " 'tu',\n",
              " 'prenez',\n",
              " 'faites',\n",
              " 'suis-je',\n",
              " 'on',\n",
              " 'comme',\n",
              " 'bouge',\n",
              " 'que',\n",
              " 'perdu.',\n",
              " 'laissez-moi',\n",
              " 'avons',\n",
              " 'venez',\n",
              " 'tranquille.',\n",
              " 'malade.',\n",
              " \"m'en\",\n",
              " 'laisse',\n",
              " 'attention.',\n",
              " 'allez',\n",
              " 'été',\n",
              " 'vais',\n",
              " 'une',\n",
              " 'là.',\n",
              " 'ils',\n",
              " 'elles',\n",
              " 'ceci.',\n",
              " 'aller',\n",
              " 'moi',\n",
              " \"j'étais\",\n",
              " 'y',\n",
              " 'vu.',\n",
              " 'vos',\n",
              " 'viens',\n",
              " 'toi.',\n",
              " 'sens',\n",
              " 'regarde',\n",
              " 'laisse-moi',\n",
              " 'demande',\n",
              " 'chez',\n",
              " 'bon',\n",
              " 'vraiment',\n",
              " 'vers',\n",
              " 'trouve',\n",
              " 'triste.',\n",
              " 'tranquille',\n",
              " 'train',\n",
              " 'sommes',\n",
              " 'soin',\n",
              " 'sans',\n",
              " 'peux',\n",
              " 'pars',\n",
              " 'ont',\n",
              " 'gagné.',\n",
              " 'décampe',\n",
              " 'comment',\n",
              " 'ceci',\n",
              " 'bonne',\n",
              " 'avec',\n",
              " 'vrai',\n",
              " 'vous.',\n",
              " 'veux',\n",
              " 'tout',\n",
              " 'sûr.',\n",
              " 'sont',\n",
              " 'se',\n",
              " 'sais',\n",
              " 'quelle',\n",
              " 'puis-je',\n",
              " 'prudente',\n",
              " 'moi.',\n",
              " 'maintenant.',\n",
              " 'lit',\n",
              " 'laissez',\n",
              " \"j'aime\",\n",
              " 'faut',\n",
              " 'essayé.',\n",
              " 'décampez',\n",
              " 'debout.',\n",
              " \"d'accord.\",\n",
              " 'chaud.',\n",
              " 'cassez-vous.',\n",
              " 'camp.',\n",
              " 'camp',\n",
              " 'attention\\u202f!',\n",
              " 'ah',\n",
              " 'tomber.',\n",
              " 'tomber',\n",
              " 'toi',\n",
              " 'temps',\n",
              " 'regardez',\n",
              " 'nouveau.',\n",
              " 'mal.',\n",
              " 'fiche',\n",
              " 'déguerpissez.',\n",
              " 'dégage\\u202f!',\n",
              " 'aucun',\n",
              " 'arrêtez',\n",
              " 'Êtes-vous',\n",
              " 'voir',\n",
              " 'vite.',\n",
              " 'problème.',\n",
              " 'pour',\n",
              " 'partir.',\n",
              " 'parle',\n",
              " 'marche.',\n",
              " \"l'écart.\",\n",
              " 'jambes',\n",
              " 'gardez',\n",
              " 'garde',\n",
              " 'gagné',\n",
              " 'fait.',\n",
              " 'est-il',\n",
              " 'entrer.',\n",
              " 'disparais',\n",
              " 'dis',\n",
              " \"d'ici.\",\n",
              " 'coup',\n",
              " 'continuez',\n",
              " 'cela.',\n",
              " 'ce',\n",
              " 'bon.',\n",
              " 'besoin',\n",
              " 'attention',\n",
              " 'attends',\n",
              " 'attendez.',\n",
              " 'attendez',\n",
              " 'arrête',\n",
              " 'aller.',\n",
              " 'vu',\n",
              " 'vraiment\\u202f?',\n",
              " 'votre',\n",
              " 'vis.',\n",
              " 'va-t-il',\n",
              " 'un.',\n",
              " 'ton',\n",
              " 'tes',\n",
              " 'souri.',\n",
              " 'sortir',\n",
              " 'signe',\n",
              " 'sensass',\n",
              " \"s'il\",\n",
              " \"s'est\",\n",
              " \"s'en\",\n",
              " 'retard.',\n",
              " 'quoi',\n",
              " 'prudent',\n",
              " 'promis.',\n",
              " 'prie.',\n",
              " 'pied.',\n",
              " 'partir\\u202f!',\n",
              " 'partir',\n",
              " 'parti.',\n",
              " 'parlez',\n",
              " 'pardon\\u202f?',\n",
              " 'pardon',\n",
              " 'paie.',\n",
              " 'oubliez',\n",
              " 'occupée.',\n",
              " 'nous.',\n",
              " 'mien.',\n",
              " 'merci',\n",
              " 'menti.',\n",
              " 'marrant.',\n",
              " \"m'a\",\n",
              " 'laissez-le',\n",
              " 'laisse-le',\n",
              " \"l'avons\",\n",
              " \"l'amour\",\n",
              " 'immobile',\n",
              " 'honnête.',\n",
              " 'haut.',\n",
              " 'gros.',\n",
              " 'fûmes',\n",
              " 'froid.',\n",
              " 'file',\n",
              " 'feu',\n",
              " 'faire',\n",
              " 'essaye.',\n",
              " 'essaie.',\n",
              " 'es-tu',\n",
              " 'doucement',\n",
              " 'dois',\n",
              " 'dit',\n",
              " 'dessus.',\n",
              " 'des',\n",
              " 'derrière',\n",
              " 'dans',\n",
              " 'cours',\n",
              " 'cool.',\n",
              " 'continue',\n",
              " 'ciao.',\n",
              " 'chercher',\n",
              " 'casse-toi.',\n",
              " 'calmez-vous',\n",
              " 'calme',\n",
              " 'bravo',\n",
              " 'baissé.',\n",
              " 'avance',\n",
              " 'attrapez',\n",
              " 'attrape',\n",
              " '«',\n",
              " 'vue.',\n",
              " 'voté.',\n",
              " 'vois.',\n",
              " 'voir.',\n",
              " 'vas-y.',\n",
              " 'vas-y',\n",
              " 'vas',\n",
              " 'va.',\n",
              " 'va-t’en\\xa0!',\n",
              " 'une.',\n",
              " 'tôt.',\n",
              " 'trouvez',\n",
              " 'trop',\n",
              " 'tiens',\n",
              " 'thé.',\n",
              " 'terre',\n",
              " 'tenez.',\n",
              " 'tenez',\n",
              " 'sortez.',\n",
              " 'sortez',\n",
              " 'sors.',\n",
              " 'sol',\n",
              " 'sienne.',\n",
              " 'sien.',\n",
              " 'seul.',\n",
              " 'senti',\n",
              " 'saute.',\n",
              " 'santé',\n",
              " 'reviens',\n",
              " 'retraite.',\n",
              " 'remercie.',\n",
              " 'recule\\u2009!',\n",
              " 'reculez.',\n",
              " 'quittez',\n",
              " 'quitte',\n",
              " 'question',\n",
              " \"qu'est-ce\",\n",
              " 'prêt.',\n",
              " 'prudente.',\n",
              " 'prudent.',\n",
              " 'problème',\n",
              " 'pouvons-nous',\n",
              " 'porte',\n",
              " 'pleuré.',\n",
              " 'pleura.',\n",
              " 'plaît.',\n",
              " 'payer.',\n",
              " 'passe',\n",
              " 'partie.',\n",
              " 'parti',\n",
              " 'parlé.',\n",
              " 'paresseux.',\n",
              " 'oust',\n",
              " 'oublié.',\n",
              " 'mort.',\n",
              " 'mienne.',\n",
              " 'mentir.',\n",
              " 'mauvais.',\n",
              " 'malade',\n",
              " 'maison.',\n",
              " 'ma',\n",
              " \"m'y\",\n",
              " 'l’ai',\n",
              " \"l'heure.\",\n",
              " \"l'aide.\",\n",
              " \"j'adore\",\n",
              " 'hors',\n",
              " 'heures',\n",
              " 'gentil.',\n",
              " 'gentil',\n",
              " 'gaffe',\n",
              " 'fous',\n",
              " 'fou.',\n",
              " 'fonctionne.',\n",
              " 'filez',\n",
              " 'fichez',\n",
              " 'fantastique\\u202f!',\n",
              " 'faire.',\n",
              " 'est-il\\u202f?',\n",
              " 'essayez',\n",
              " 'essayer.',\n",
              " 'essaie',\n",
              " 'entre.',\n",
              " 'emporté.',\n",
              " 'emporté',\n",
              " 'emploi',\n",
              " 'détends-toi',\n",
              " 'dégage',\n",
              " 'dirigez-vous',\n",
              " 'dirige-toi',\n",
              " 'devenu',\n",
              " 'c’est',\n",
              " 'cous',\n",
              " 'courir.',\n",
              " 'chante',\n",
              " 'certain.',\n",
              " 'calme\\u202f!',\n",
              " 'calme-toi.',\n",
              " \"c'était\",\n",
              " 'boulot',\n",
              " 'bougez',\n",
              " 'bizarre.',\n",
              " 'bientôt',\n",
              " 'avez',\n",
              " 'avance.',\n",
              " 'assieds-toi',\n",
              " 'asseyez-vous.',\n",
              " 'asseyez-vous',\n",
              " 'as',\n",
              " 'arrête-toi',\n",
              " 'allons',\n",
              " 'allez\\u202f!',\n",
              " 'allez-y',\n",
              " 'ainsi',\n",
              " 'ai-je',\n",
              " 'éveillé.',\n",
              " 'équitable',\n",
              " 'écrit.',\n",
              " 'écoulé.',\n",
              " 'échoué.',\n",
              " 'Étudiez',\n",
              " 'Étudie',\n",
              " 'Écarte-toi',\n",
              " '».',\n",
              " 'yeux.',\n",
              " 'vôtre.',\n",
              " 'vérifie',\n",
              " 'vus.',\n",
              " 'vues.',\n",
              " 'voyez',\n",
              " 'voyait.',\n",
              " 'vote.',\n",
              " 'voilà.',\n",
              " 'voici.',\n",
              " 'vite\\u202f!',\n",
              " 'visez',\n",
              " 'vise',\n",
              " 'vin.',\n",
              " 'ville',\n",
              " 'vigilants.',\n",
              " 'vigilant.',\n",
              " 'vieux.',\n",
              " 'viens\\xa0!',\n",
              " 'vieille.',\n",
              " 'venez\\u202f!',\n",
              " 'vais.',\n",
              " \"va-t'en\",\n",
              " 'tête.',\n",
              " 'tricote.',\n",
              " 'trichent.',\n",
              " 'trente.',\n",
              " 'travailler.',\n",
              " 'tragique',\n",
              " 'tracassez',\n",
              " 'tracasse',\n",
              " 'touche',\n",
              " 'tombée.',\n",
              " 'tombé.',\n",
              " 'tomber\\u202f!',\n",
              " 'toi\\u202f!',\n",
              " 'tiré.',\n",
              " 'tire.',\n",
              " 'tire-toi',\n",
              " 'timide.',\n",
              " 'tenté.',\n",
              " 'tellement',\n",
              " 'tard.',\n",
              " 'tard',\n",
              " \"t'aime.\",\n",
              " \"t'aime\",\n",
              " \"t'ai\",\n",
              " 'sérieux\\u202f?',\n",
              " 'sérieux',\n",
              " 'sérieusement',\n",
              " 'sérieuse',\n",
              " 'sur',\n",
              " 'super\\u202f!',\n",
              " 'sud.',\n",
              " 'sortez\\u202f!',\n",
              " 'sors',\n",
              " 'simplement.',\n",
              " 'simplement',\n",
              " 'signez',\n",
              " 'seule.',\n",
              " 'seule',\n",
              " 'seul',\n",
              " 'sentez',\n",
              " 'satisfaite',\n",
              " 'satisfait',\n",
              " 'saoul.',\n",
              " 'salut',\n",
              " 'réveillé.',\n",
              " 'réveillez-vous',\n",
              " 'réveille-toi',\n",
              " 'réussi\\u202f!',\n",
              " 'réparai.',\n",
              " 'ruiné.',\n",
              " 'route.',\n",
              " 'rouler',\n",
              " 'rigolo.',\n",
              " 'riche.',\n",
              " 'ricané.',\n",
              " 'revenez',\n",
              " 'retrait.',\n",
              " 'reposée.',\n",
              " 'reposé.',\n",
              " 'rentrez',\n",
              " 'rentre',\n",
              " 'relève.',\n",
              " 'relaxe',\n",
              " 'relais.',\n",
              " 'regardé.',\n",
              " 'refuse.',\n",
              " 'reculez\\u2009!',\n",
              " 'recule.',\n",
              " 'recul.',\n",
              " 'rappelle.',\n",
              " 'rapide.',\n",
              " 'raison.',\n",
              " 'qui.',\n",
              " \"qu'on\",\n",
              " \"qu'as-tu\",\n",
              " 'pue.',\n",
              " 'prête',\n",
              " 'près.',\n",
              " 'prudents.',\n",
              " 'prudents',\n",
              " 'prudentes.',\n",
              " 'prudentes',\n",
              " 'proximité.',\n",
              " 'propre.',\n",
              " 'problème\\u202f!',\n",
              " 'pris',\n",
              " 'prie',\n",
              " 'prenez-le.',\n",
              " 'poussez-vous.',\n",
              " 'pousse-toi.',\n",
              " 'poursuivez',\n",
              " 'poursuis',\n",
              " 'pleurait.',\n",
              " 'plein.',\n",
              " 'plaît-il\\u202f?',\n",
              " 'plaît',\n",
              " 'plait-il\\u202f?',\n",
              " 'plaisir.',\n",
              " 'pipeau',\n",
              " 'peu',\n",
              " 'petite.',\n",
              " 'perdue.',\n",
              " 'perdu',\n",
              " 'payé.',\n",
              " 'pas\\xa0!',\n",
              " 'pars.',\n",
              " 'parlé',\n",
              " 'parlez-moi',\n",
              " 'oublie-le',\n",
              " 'oublie',\n",
              " 'oiseaux',\n",
              " 'occupé.',\n",
              " 'obéi.',\n",
              " 'nôtre.',\n",
              " 'nue.',\n",
              " 'nu.',\n",
              " 'nourriture.',\n",
              " 'notes.',\n",
              " 'non.',\n",
              " 'nagèrent.',\n",
              " 'nageaient.',\n",
              " \"n'y\",\n",
              " \"n'importe\",\n",
              " \"n'est\",\n",
              " 'mouvement',\n",
              " 'mourir.',\n",
              " 'mouillé.',\n",
              " 'morte.',\n",
              " 'monde',\n",
              " 'mon',\n",
              " 'miens.',\n",
              " 'miennes.',\n",
              " 'mettez',\n",
              " 'met',\n",
              " 'merci.',\n",
              " 'mens',\n",
              " 'marché.',\n",
              " 'maman',\n",
              " 'malin',\n",
              " 'maison',\n",
              " 'maintenant\\xa0!',\n",
              " 'magnifique\\u202f!',\n",
              " 'lève-toi.',\n",
              " 'lâche-toi',\n",
              " 'lire.',\n",
              " 'levée',\n",
              " 'levé',\n",
              " 'laissez-nous',\n",
              " 'laisse-nous',\n",
              " \"l'évidence.\",\n",
              " \"l'ouest.\",\n",
              " \"l'intérieur.\",\n",
              " \"l'exercice.\",\n",
              " \"l'est.\",\n",
              " \"l'envie.\",\n",
              " \"l'aide\\u202f!\",\n",
              " \"l'abri\\xa0!\",\n",
              " \"l'a\",\n",
              " 'j’y',\n",
              " 'jésus',\n",
              " 'juste.',\n",
              " 'juste',\n",
              " 'juré.',\n",
              " 'joué\\u202f!',\n",
              " 'joli',\n",
              " 'joignez-vous',\n",
              " \"j'y\",\n",
              " \"j'irai.\",\n",
              " \"j'essaye.\",\n",
              " \"j'espère\",\n",
              " 'immobiles',\n",
              " 'ici\\u202f!',\n",
              " 'ici',\n",
              " 'humeur.',\n",
              " 'honnêtes.',\n",
              " 'homme.',\n",
              " 'homme',\n",
              " 'heure',\n",
              " 'hais.',\n",
              " 'génial\\u202f!',\n",
              " 'génial',\n",
              " 'grave.',\n",
              " 'gloussé.',\n",
              " 'gentille',\n",
              " 'gardes.',\n",
              " 'gagnèrent.',\n",
              " 'gaffe.',\n",
              " 'fuyons',\n",
              " 'fuyez',\n",
              " 'fus',\n",
              " 'foutre',\n",
              " 'fort\\u202f!',\n",
              " 'formidable',\n",
              " 'fonctionnera.',\n",
              " 'file.',\n",
              " 'ferai',\n",
              " 'fauché.',\n",
              " 'fatigué',\n",
              " 'faites-le',\n",
              " 'fais-le',\n",
              " 'fainéant.',\n",
              " 'faim',\n",
              " 'faible.',\n",
              " 'excusez-moi.',\n",
              " 'excuse-moi.',\n",
              " 'excellent\\u202f!',\n",
              " 'eu',\n",
              " 'et',\n",
              " 'est-ce\\u202f?',\n",
              " 'espèce',\n",
              " 'entrez\\u202f!',\n",
              " 'entrer',\n",
              " 'entre',\n",
              " 'encore.',\n",
              " 'détendue.',\n",
              " 'détendu.',\n",
              " 'détends-toi\\u202f!',\n",
              " 'détends-toi.',\n",
              " 'détendez-vous\\u202f!',\n",
              " 'désolé.',\n",
              " 'déplacez-vous.',\n",
              " 'déplace-toi.',\n",
              " 'dégagez',\n",
              " 'dégage.',\n",
              " 'défaits.',\n",
              " 'défaites.',\n",
              " 'dure.',\n",
              " 'dur.',\n",
              " 'dj.',\n",
              " 'dit\\u202f?',\n",
              " 'disparais\\u202f!',\n",
              " 'discutons.',\n",
              " 'devant',\n",
              " 'deux.',\n",
              " 'descends.',\n",
              " 'dernière.',\n",
              " 'dernier.',\n",
              " 'demandez',\n",
              " 'debout',\n",
              " 'davantage.',\n",
              " \"d'aller\",\n",
              " 'cédé.',\n",
              " 'cuire.',\n",
              " 'crié.',\n",
              " 'court.',\n",
              " 'cours\\u202f!',\n",
              " 'courez\\u202f!',\n",
              " 'cou',\n",
              " 'connais.',\n",
              " 'confiance.',\n",
              " 'confiance',\n",
              " 'conduis.',\n",
              " 'compris.',\n",
              " 'commentaire.',\n",
              " 'commencez.',\n",
              " 'commencez',\n",
              " 'commence',\n",
              " 'colère.',\n",
              " 'ci-dessous.',\n",
              " 'chouette',\n",
              " 'chose.',\n",
              " 'choisis-en',\n",
              " 'chiens',\n",
              " 'calmos',\n",
              " 'calmes',\n",
              " 'cafard.',\n",
              " 'brève.',\n",
              " 'bref.',\n",
              " 'bras',\n",
              " 'bouger.',\n",
              " 'bouclez-la',\n",
              " 'bonne.',\n",
              " 'blessé.',\n",
              " 'blague',\n",
              " 'bidon.',\n",
              " 'bibi\\u202f!',\n",
              " 'besoin.',\n",
              " 'battus.',\n",
              " 'battues.',\n",
              " 'avoir',\n",
              " 'avant\\u202f!',\n",
              " 'avant.',\n",
              " 'autre',\n",
              " 'assise.',\n",
              " 'assis',\n",
              " 'arrière.',\n",
              " 'arrière',\n",
              " 'apportez',\n",
              " 'apporte',\n",
              " 'application.',\n",
              " 'appelle',\n",
              " 'ans.',\n",
              " 'amusée.',\n",
              " 'amusé.',\n",
              " 'amusez-vous',\n",
              " 'allons-y',\n",
              " 'allongée,',\n",
              " 'allongé,',\n",
              " 'allez-vous-en\\xa0!',\n",
              " 'aller!',\n",
              " 'alerte.',\n",
              " 'alentour',\n",
              " 'aille.',\n",
              " 'aidé.',\n",
              " 'aidez',\n",
              " 'aide-moi',\n",
              " 'aboient.',\n",
              " 'abandonne\\u202f!',\n",
              " 'aaah',\n",
              " ':',\n",
              " 'êtes',\n",
              " 'équitables',\n",
              " 'équipe.',\n",
              " 'épaules.',\n",
              " 'énervé.',\n",
              " 'éloigné',\n",
              " 'écrasée.',\n",
              " 'écrasé.',\n",
              " 'écouté.',\n",
              " 'échauffer',\n",
              " 'ça\\u202f!',\n",
              " 'Épousez-moi',\n",
              " 'Épouse-moi',\n",
              " 'Écrivez-moi',\n",
              " 'Écrivez',\n",
              " 'Écris-moi',\n",
              " 'Écoutez',\n",
              " 'Échauffez-vous',\n",
              " 'Échauffe-toi',\n",
              " 'Écartez-vous',\n",
              " '»',\n",
              " 'waouh\\xa0!',\n",
              " 'wah\\xa0!',\n",
              " 'vérifiez',\n",
              " 'vérifierai.',\n",
              " 'vu\\u202f!',\n",
              " 'vrai\\u202f!',\n",
              " 'vrai,',\n",
              " 'voyons',\n",
              " 'voyais',\n",
              " 'votons.',\n",
              " 'vomi.',\n",
              " 'voler.',\n",
              " 'volent.',\n",
              " 'vois',\n",
              " 'voir\\xa0!',\n",
              " 'voilà',\n",
              " 'voiles.',\n",
              " 'vivrai.',\n",
              " 'vivant\\xa0!',\n",
              " 'vivante.',\n",
              " 'vivant.',\n",
              " 'vite',\n",
              " 'viendrai.',\n",
              " 'vie.',\n",
              " 'vie',\n",
              " 'veux.',\n",
              " 'vert.',\n",
              " 'verse.',\n",
              " 'verrouillez-le.',\n",
              " 'verrouillez-la.',\n",
              " 'verrouille-le.',\n",
              " 'verrouille-la.',\n",
              " 'venue.',\n",
              " 'venu.',\n",
              " 'venu',\n",
              " 'venir.',\n",
              " 'venir',\n",
              " 'veinarde.',\n",
              " 'veinard.',\n",
              " 'va\\xa0!',\n",
              " 'vas-tu',\n",
              " 'valise.',\n",
              " 'va-t’en',\n",
              " 'va,',\n",
              " 'utilisez',\n",
              " 'utilise',\n",
              " 'usage.',\n",
              " 't’as',\n",
              " 't’adore',\n",
              " 'tête',\n",
              " 'téléphoné.',\n",
              " 'téléphonai.',\n",
              " 'télé.',\n",
              " 'tuez-le.',\n",
              " 'tuez-la.',\n",
              " 'tuez',\n",
              " 'tue-le.',\n",
              " 'tue-la.',\n",
              " 'tue',\n",
              " 'trépasser',\n",
              " 'trébuché.',\n",
              " 'très',\n",
              " 'trouvé.',\n",
              " 'trouvai.',\n",
              " 'trompé-je\\u202f?',\n",
              " 'trompe',\n",
              " 'trois',\n",
              " 'tristesse.',\n",
              " 'tristes.',\n",
              " 'triché.',\n",
              " 'triche.',\n",
              " 'tressailli.',\n",
              " 'trente',\n",
              " 'trempée.',\n",
              " 'tremblé.',\n",
              " 'travail\\u202f!',\n",
              " 'travaillons',\n",
              " 'travaillerai.',\n",
              " 'travaille.',\n",
              " 'travail',\n",
              " 'tranquillisez-vous.',\n",
              " 'tranquilles.',\n",
              " 'tragédie',\n",
              " 'tout.',\n",
              " 'tourne.',\n",
              " 'tourne',\n",
              " 'touchée',\n",
              " 'touché',\n",
              " 'touche\\u202f!',\n",
              " 'touchez-le.',\n",
              " 'touchez-la.',\n",
              " 'touchez',\n",
              " 'touche-le.',\n",
              " 'touche-la.',\n",
              " 'tort',\n",
              " 'tombé\\xa0?',\n",
              " 'tombés.',\n",
              " 'tombés',\n",
              " 'tombées.',\n",
              " 'toi,',\n",
              " 'tocade.',\n",
              " 'tiré',\n",
              " 'tirez',\n",
              " 'tirerai.',\n",
              " 'tire',\n",
              " 'timides.',\n",
              " 'tiens-toi',\n",
              " 'tienne.',\n",
              " 'tien.',\n",
              " 'terrible.',\n",
              " 'terre\\xa0!',\n",
              " 'tenue',\n",
              " 'tenu',\n",
              " 'tenterons.',\n",
              " 'tenez-vous',\n",
              " 'teint',\n",
              " 'tchin-tchin',\n",
              " 'tatillonne.',\n",
              " 'tatillon.',\n",
              " 'taisez-vous\\u202f!',\n",
              " 'taisez-vous.',\n",
              " 'tais-toi',\n",
              " 'taillez-vous',\n",
              " 'taille-toi',\n",
              " 'tabou.',\n",
              " \"t'échauffer\",\n",
              " \"t'inquiète\",\n",
              " \"t'es\",\n",
              " \"t'envie.\",\n",
              " \"t'entends.\",\n",
              " \"t'en\",\n",
              " \"t'as\",\n",
              " \"t'approche\",\n",
              " \"t'adore.\",\n",
              " 'sûre.',\n",
              " 'sûr',\n",
              " 'sérieux\\u202f!',\n",
              " 'sérieux.',\n",
              " 'sérieuses',\n",
              " 'sérieuse.',\n",
              " 'sécurité.',\n",
              " 'syncope.',\n",
              " 'survécu.',\n",
              " 'sursauté.',\n",
              " 'suppose.',\n",
              " 'supplie.',\n",
              " 'super.',\n",
              " 'super',\n",
              " 'sujet',\n",
              " 'suivez-nous',\n",
              " 'suivez-le\\u202f!',\n",
              " 'suivez',\n",
              " 'suis\\u202f!',\n",
              " 'suisse.',\n",
              " 'suis.',\n",
              " 'suis-nous',\n",
              " 'suis-moi.',\n",
              " 'suis-le\\u202f!',\n",
              " 'suffit\\u202f!',\n",
              " 'stricte.',\n",
              " 'strict.',\n",
              " 'stop\\u202f!',\n",
              " 'stoppez',\n",
              " 'soûl.',\n",
              " 'souviens.',\n",
              " 'sournoise.',\n",
              " 'sournois.',\n",
              " 'souris',\n",
              " 'souriez\\u202f!',\n",
              " 'souriez\\u2009!',\n",
              " 'sourde.',\n",
              " 'sourd.',\n",
              " 'sourcils.',\n",
              " 'soupiré.',\n",
              " 'souhaits\\u202f!',\n",
              " 'souffle',\n",
              " 'soucions.',\n",
              " 'soucie\\u202f?',\n",
              " 'souci.',\n",
              " 'sortie.',\n",
              " 'sorti.',\n",
              " 'sommeil\\u202f!',\n",
              " 'somme',\n",
              " 'sombre.',\n",
              " 'soit-il.',\n",
              " 'sobre.',\n",
              " 'skier.',\n",
              " 'sincère.',\n",
              " 'simple.',\n",
              " 'silencieux.',\n",
              " 'signe.',\n",
              " 'sifflé.',\n",
              " 'siens.',\n",
              " 'si',\n",
              " 'sexy.',\n",
              " 'seuls',\n",
              " 'seules',\n",
              " 'sers.',\n",
              " 'serrez-moi',\n",
              " 'serre-moi',\n",
              " 'serais',\n",
              " 'sept',\n",
              " 'sentis',\n",
              " 'sentie',\n",
              " 'sentais',\n",
              " 'sent',\n",
              " 'secouez-vous',\n",
              " 'secoue-toi',\n",
              " 'savons.',\n",
              " 'savait.',\n",
              " 'savais.',\n",
              " 'sauvez-vous',\n",
              " 'sauvez',\n",
              " 'sauve-toi',\n",
              " 'sauve',\n",
              " 'sauté.',\n",
              " 'sautez',\n",
              " 'sauter.',\n",
              " 'saute',\n",
              " 'sauta.',\n",
              " 'satisfaits',\n",
              " 'satisfaites',\n",
              " 'sang-froid.',\n",
              " 'salut.',\n",
              " 'salut,',\n",
              " 'sale.',\n",
              " 'sait\\u202f?',\n",
              " 'sait.',\n",
              " 'saisissez-vous',\n",
              " 'saisis-toi',\n",
              " 'sais.',\n",
              " 'sagesse',\n",
              " 'sac.',\n",
              " 'sable.',\n",
              " \"s'envole.\",\n",
              " \"s'enfuit.\",\n",
              " \"s'arrache.\",\n",
              " \"s'agit\",\n",
              " 'réveille-toi\\u202f!',\n",
              " 'réussi.',\n",
              " 'réponds',\n",
              " 'répondez-moi.',\n",
              " 'répondez',\n",
              " 'réparée.',\n",
              " 'réparé.',\n",
              " 'réparez',\n",
              " 'répare',\n",
              " 'réaliste',\n",
              " 'râlé.',\n",
              " 'ruinée.',\n",
              " 'rouge.',\n",
              " 'ronfle\\xa0?',\n",
              " 'ronfle.',\n",
              " 'romps',\n",
              " 'rompez',\n",
              " 'rigolé.',\n",
              " 'rigole',\n",
              " 'rien.',\n",
              " 'rien',\n",
              " 'ri.',\n",
              " 'reçu',\n",
              " 'revoyure.',\n",
              " 'revoir.',\n",
              " 'revoilà.',\n",
              " 'revenu.',\n",
              " 'retirez-vous.',\n",
              " 'retire-toi\\u2009!',\n",
              " 'retard',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rYz3z6aCyf8E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}