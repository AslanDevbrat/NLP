{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMFDiQnYdPzdhsle101WWoS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AslanDevbrat/NLP/blob/main/sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Processing"
      ],
      "metadata": {
        "id": "n_D1XjVpXecR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "J872ZMyQXeEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fG8QoDWA_2uA",
        "outputId": "9755fd5f-47c1-41d2-f8d7-f8893ec8ea6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deep-learning-with-tensorflow-2'...\n",
            "remote: Enumerating objects: 28, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 28 (delta 16), reused 28 (delta 16), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (28/28), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Neuralearn/deep-learning-with-tensorflow-2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6buLmvHGPr6",
        "outputId": "1077c92c-e8d8-4daf-b63e-1727ab8f2f16"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-18 11:07:31--  https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  21.4MB/s    in 4.9s    \n",
            "\n",
            "2022-07-18 11:07:36 (16.2 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xzf /content/aclImdb_v1.tar.gz"
      ],
      "metadata": {
        "id": "Bc4In9jsGXm2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from tensorflow.keras.preprocessing import text_dataset_from_directory\n",
        "from tensorflow.keras.layers import SimpleRNN,LSTM, Dense, Reshape, Embedding,GRU\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40gSjv4bADoL",
        "outputId": "2b555d0e-b1d3-4262-97bb-e61799cc62ae"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_directory = \"/content/aclImdb/train\"\n",
        "val_directory = \"/content/aclImdb/test\""
      ],
      "metadata": {
        "id": "OMonVZ_PHB2Y"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/aclImdb/train/unsup /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbwztOYsJmsc",
        "outputId": "d772a743-98fd-47d9-87ba-76c992513b69"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat '/content/aclImdb/train/unsup': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = text_dataset_from_directory(\n",
        "    train_directory,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiT2JT-GHRtd",
        "outputId": "dc7a3b88-4963-4ce2-b1a7-63177bb3eb1f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = text_dataset_from_directory(\n",
        "    val_directory,\n",
        "    shuffle = True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDmWPUVKHm6i",
        "outputId": "a2642f5c-ea6e-46d4-de3c-f18978697c9a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in train_dataset.take(1):\n",
        "  print(x)\n",
        "  print()\n",
        "  print(y)"
      ],
      "metadata": {
        "id": "XTijiiqdJ1zr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a8d22e0-7638-43ac-9cc2-da392044b3c8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'The horse is indeed a fine animal. Picturesque depictions of wild horses and their grace could never have been more majestic in an animation flick.<br /><br />The animation is simply stupendous. The fine animation forms the backbone of the beauty that the horses embolden across the flick. More so when the stallion traverses diverse terrain, jumps across cliffs and braves waters. <br /><br />Soundtrack too is very impressive. The wonderful instrumental music lures you to appreciate the movie. <br /><br />\"They say the story of the west was written from the saddle of a horse . \" huh? Well ,The story of a fine horse sure was written from the saddle of the west .<br /><br />All in all, this movie is clearly up there with the best .It is one of the best animation flicks i have watched. Would be a very fine choice on a lonely night. An easy 9/10.'\n",
            " b'I am completely baffled as to why this film is even liked, let alone held in such high regard, especially by so many critics who are, otherwise, quite sensible.<br /><br />There is one key word which describes this film to its core - irritating.<br /><br />The most easily explained example of this is the director\\'s use - or, more accurately, abuse - of music. In the first half, a really dull reggae tune is played about three times (when once is too often). But in the second half, The Mommas And The Papas \"California Dreamin\\'\" is played at least seven times, usually at top volume. Godsakes, whether you liked the song or not beforehand, you\\'d be thoroughly sick of it by the end. Just think, some people claim to have seen this film four or five times. This means they\\'ve listened to California Dreamin either 28 or 35 times.....<br /><br />All of this needless hyper-repetition (it contributes nothing to the story) could possibly be excused if the remainder of the film had any lingering merit, or if the story was in any way involving.<br /><br />But it ain\\'t.<br /><br />The only aspect I found likeable was Bridgette Lin\\'s charging around and still playing Asia The Invincible in a raincoat and sunnies. Even this wore off fairly quickly.<br /><br />I\\'m sure this film\\'s undeserved high reputation will convince many poor suckers to go and see it.<br /><br />I can only warn you - if you\\'ve never seen a HK movie before, don\\'t start with this one.<br /><br />If you feel compelled to watch it, avoid at all costs seeing it in a cinema. The fast-forward and mute buttons are essential tools for survival here.<br /><br />You have been warned !'\n",
            " b'Hines and Goforth, the perpetrators of this crime, begin on the wrong foot first step, by assuming that Wells wrote Gothic horror and that all of his lines are meant to be taken seriously. That simply isn\\'t true. Wells was very much an inheritor of the Enlightenment, and his main concern was that Victorian self-satisfaction might leave the British unprepared for the world the new technology could produce - both the good and the bad.<br /><br />Two terrible consequences follow - the protagonist is portrayed as a wimpy screamer (I was reminded of Fay Wray in the original King Kong), rather than a man struggling to live out the ironies of an unbelievable catastrophe; and the dialog reeks of \\'Victorianisms\\' uttered seriously that Welles clearly meant to be taken tongue in cheek.<br /><br />All of this looks suspiciously like Ed Wood with an enormous budget to waste on CGI effects - which by the way are so poorly accomplished, the Warner Bros. cartoon factory of the 1940s could have done a better job. (Gobs of spattered blood looked like red balloons, I expected them to float away any minute.) Think The Yellow Submarine as done by the old EC Comics.<br /><br />Worse yet is the loss of theme, which robs the film of any reason to exist. Although the makers of this film return the story to its Victorian era, they utterly miss the uncanny way Wells\\' story predicted many of the horrors of the First World War - a fact not unnoticed by Wells himself, who, after the war, reworked the theme in The Shape of Things to Come.<br /><br />Without any theme, all we have here are a lot of people running around getting blasted into cartoon balloons, when they\\'re not trying out for a high school production of a drunken student\\'s rewrite of Macbeth.<br /><br />Really, this is the worst, most senseless piece of drivel I have suffered through since a friend talked me into seeing the Eastern European cartoon \"Fantastic Planet\" thirty years ago. That film was so pretentiously dull, my friend and I and two total strangers gave up ridiculing it about half-way through, and sat near the screen playing cards, using the movie as light by which to see the cards - its only usefulness, as far as any of us could tell.<br /><br />But I already have electric lighting in my apartment, so I didn\\'t need this put-down of Wells for anything.<br /><br />Do not avoid this film - steal every copy you can (don\\'t pay a cent) and burn each and every one of them. God in his wisdom created us just for this purpose.'\n",
            " b'Indian Summer! It was very nostalgic for me. I found it funny, heartwarming, and absolutely loved it! Anyone who went to camp as a kid and wishes at times they could go back to the \"good Ole\\' days\" for a brief time really needs to see this one! It starts out as 20 years later, a group of old campers returns for a \"reunion\". I won\\'t comment on the plot anymore cause you have to see it for yourself. The actors were great, and it contains an all star cast. Everyone in it played a terrific role. You actually felt like you were a part of the movie watching it. Alan Arkin was especially good in his role as Uncle Lou. He plays the kind of guy that everyone wishes they had in their lives. This is also a good family movie for the most part. I would suggest this one to anybody in a heartbeat! HIGHLY Recommended!'\n",
            " b\"I've been looking for the name of this film for years. I was 14 when I believe it was aired on TV in 1983. All I can remember was it was about a teenaged girl, alone, having survived a plane crash AND surviving the Amazon. I remember people were looking for her(family) and that she knew how to take care of herself---she narrates the story and I vividly remember about her knowing that bugs were under her skin. I don't remember much else about this movie, and want to see it again--if this IS the same one--and if any of you have a copy, could you email me at horsecoach4hire@hotmail.com? I'd be curious to attain a copy to see if it is in fact the same film I remember. It was aired on Thanksgiving(US) in 1983, and I was going through problems of my own and this film really impacted heavily on me. Thanks in advance!\"\n",
            " b\"I see a lot of people liked this movie. To me this was a movie made right of writing 101 and the person failed the class. From the time Lindsey Price the videographer shows up until the end the movie was very predictable. I kept on watching to see if it was going anywhere.<br /><br />First we have the widowed young father. Clich\\xc3\\xa9 #1 movies/TV always kill off the the mother parent if the child is a girl, or a brood of boys so the single father can get swoon over his dead wife and seem completely out of his element taking care of the children. Starting from from My 3 Sons to 2 1/2 Dads. These movies are usually dramas and comedies are TV shows.<br /><br />Clich\\xc3\\xa9 # 2 When a pushy woman has a video camera in her hand she will play a big part in the movie. And will always have solutions or even if that person is a airhead <br /><br />Clich\\xc3\\xa9 #3 If the person in peril is a foreigner they have to be of Latino origin. And they must be illegal. Apparently there are no legal Latino's and illegal Europeans, unless if there is a IRA element involved.<br /><br />Clich\\xc3\\xa9 #4 The said Latino must be highly educated in his native country. In this case he was a Profesor who made 200 per month. And the said highly educated Latino must now act like he hasn't brain in his head now and lets the air head side kick take over.<br /><br />Clich\\xc3\\xa9 #5 The crime the person committed really wasn't a crime but a accident. But because in this case he has lost all of the sense he had when he crossed the boarder he now acts like a blithering idiot and now has put his own daughter in peril by taking her along on a fruitless quest to the border with the idiot side kick.<br /><br />Clich\\xc3\\xa9 #6 One never runs over a hoodlum running from a crime , but some poor little cute kid. This is because the parents of the child have to play a big part of the movie, and because the the person who accidentally killed the child can have ridiculous interaction with the parents.<br /><br />Clich\\xc3\\xa9 #7 Name me one movie in which one cop is not the angry vet and they get paired up with a rookie. Even if they are homicide detectives who have to be the most experienced cops on a police Force. Sev7n and Copy cat and Law and Order come to mind right away. And the vet even though gruff on the outside has a heart of gold.<br /><br />Clich\\xc3\\xa9 #8 Let's go and round up some unemployed Soap Stars. Now I like Lindsey Price. But Susan Haskell IMO can not act her way out of a paper bag and when she use to be on One Life To Live as Marty he swayed from right to left every time she opened her mouth. It use to get me sea sick. She might be anchored on land better now, but she still cannot act.<br /><br />The movie might have been more insightful if it wasn't filled with clich\\xc3\\xa9s. I don't think a movie has to be expensive or cerebral to be good. But this was just bad.<br /><br />***SPOILER**** Now I am not going to spoil the ending. Oh heck I will because I feel it will be a disservice to humanity to let a person waste time they will never get back looking at this movie. It involves Clich\\xc3\\xa9 #6 and #7. Unless a person has never seen a movie before you had to see what was coming. The father makes even a dumber mistake runs from the cops at the end and gets shot by the angry veteran, who all of a sudden is very upset. You would think she thought the poor guy was innocent all through the movie and she shot him by mistake. When she didn't. Now for the little girl who the dad brought along with him. Guess what happen to her? Times up, she ends up living with the family whose child was killed by her father!! Come on! You all knew that was going to happen, because she is a replacement child!! That is why she did not go and live with the Lindey Price character. <br /><br />This movie was a insult as far as I was concerned. Because there were so many avenues this movie could of explored and went down but it chose to take the clich\\xc3\\xa9 ridden one. The 2 stars are for 2 of the stars, the little girl, who I thought was very good and Lindsey Price who character was annoying but she did what she could with it. My advice is take a vice and squeeze your head with it instead of looking at this dreck\"\n",
            " b'This is just plain bad. Sometimes remakes, even if they stray from the original, are good on their own. They can bring another viewpoint and achieve a certain interpretation that makes them unique and enjoyable. This was as poorly thought out and carried out as can be. This wasn\\'t any good even standing on it\\'s own. Viggo Mortenson is a top-notch actor, but some of his selections of roles and projects leaves something to be desired. The original \"Vanishing Point\" was such a thrilling, psychological adventure; this is not an adventure at all, and is not enjoyable or entertaining whatsoever. This was made from a by-the-numbers approach to film-making, stuffing in plot points that someone in Hollywood believes will please what they see as today\\'s film-going audience. Basically, they see us as a bunch of idiots. It\\'s insulting that someone will put this out as a feature film, and even attempt to remake a cult classic this sloppily. The manipulative plot devices, the \"make-it-obvious-so-they-don\\'t-miss-the-point\" aspects, ridiculous dialogue, stereotyped characters, amateurish direction...<br /><br />This is plain bad....'\n",
            " b'If you have ever seen a movie by Brian Avenet-Bradley and compares it to the feedbacks it gets on IMDb, you know that most of the comments and votes are faked. TRUST ME: you will be bored! People of the production team write their feedback themselves (sometimes they even admit it). But that\\'s not enough: They also click constantly \"no\" whenever there is a negative comment on the movie. That\\'s why negative critics are always placed behind the hyped ones.<br /><br />The movie itself is bad, bad, bad: bad acting, bad lighting, bad script, bad ending. Believe me now! If not, you will believe me later!<br /><br />Brian Avenet-Bradley might be quite a good business man. Otherwise it cannot be explained that he finds people who still finance his movies. (Okay, they are cheap, but nevertheless.) But as a creative person, he is a complete failure.'\n",
            " b'This is the worst movie I have seen since \"I Know Who Killed Me\" with Lindsey Lohan. <br /><br />After watching this movie I can assure you that nothing but frustration and disappointment await you should you choose to go see this. Hey, Tim Burton, I used to be a big fan of yours... did you even screen this movie? I mean seriously, what the f%#k?<br /><br />Without giving anything away, here is the story in a vague nutshell... Nine wakes up, he does stuff, his actions and decisions are irrelevant... and the movie ends. Oh wait... here comes a spoiler...<br /><br />Spoiler alert! Spoiler alert! At the end of the movie.... it rains. I think a part of my soul died while watching this movie.'\n",
            " b'Does anyone know, where I can see or download the \"What I like about you\" season 4 episodes in the internet? Because I would die to see them and here in Germany there won\\'t be shown on TV. Please help me. I wanna see the season 4 episodes badly. I already have seen episode 4 and episode 18 on YouTube. But I couldn\\'t find more episodes of season 4. Is there maybe a website where I can see the episodes? Because I\\'ve read some comments in forums from Germany and there were people which had already seen the season 4 episodes even though they haven\\'t been shown at TV in Germany. I am happy about every information I can get. Thanks Kate'\n",
            " b'I just don\\'t see how a Concorde-New Horizons film directed by Jim Wynorski and featuring the acting talents of Andrew Stevens and a puppet could be bad. It just boggles the mind, doesn\\'t it?<br /><br />Well, let\\'s make no mistake about it. \"Munchie Strikes Back\" is indeed a bad film. Munchie is a puppet who has been around for many centuries. For reasons not fully explained until the end of the film, he is sent to Earth to help a single mother and her son. The mom\\'s problem (her main problem at least) is that she has a balloon payment due on her mortgage in two weeks...to the not-so-tiny tune of $20,000. Ouch. She can\\'t come up with the money because she just got fired. OK...JUST is the key word in that sentence. What the...? Was she planning on paying it off with a single paycheck? Maybe it would\\'ve been a good idea to have spent the last several years saving up for it...ya think?<br /><br />Munchie has magical powers similar to those a genie would possess...but there isn\\'t a limit on the number of wishes you can make! Munchie gets the boy a bunch of fancy stuff for one night but then the kid asks for it to be sent back to the mall Munchie was \"borrowing\" it from. The annoying furball also uses his otherworldly skills to help the boy win a baseball game by means of cheating. A baseball is hit so hard that it orbits the Earth several times. Sadly, those dumb parents watching the game don\\'t think it\\'s at all strange. Hmm.<br /><br />Anyway, I\\'d like to wrap this up because this has already drained away enough of my lifeforce as it is. You\\'ll be truly moved by the scene where Leslie-Anne Down, playing the mother, kicks a dog which is yapping at her. Your heart will melt at her charm when she notices dollar bills fluttering down on her front yard and she wonders how it could be snowing during the summer. \"Munchie Strikes Back\"\\'s credits promised another film to follow entitled, I believe, \"Munchie Hangs Ten\". To date, the movie viewing public has been robbed of what would surely have been a cinematic tour de force. Heh. 1/10'\n",
            " b'Excellent film dealing with the life of an old man as he looks back over the years. Starting around 1910, he reminisces about his boy and young adulthood; his family, friends, romances, etc. Very nostalgic piece with a bittersweet finale....\"all things in life come together as one, and a river runs through it. And that river haunts me.\" Worth seeing.'\n",
            " b'There are movies, and there are films. Movies are more often than not merely cinematic \"candy,\" whereas films are true works of art. Fraulein Doktor is certainly well-placed in the latter. As most viewers, I was highly impressed with the battle scenes, but the poignancy of the portrayal of the central character is what I consider to be the most sterling quality of the film. Having done everything possible to serve her country as a true daughter of Deutschland, all the while in the throes of morphine addiction, die Fraulein is treated very shabbily by the German high command despite all of her efforts. The scene in which the Doktor is being conveyed in the rear seat of a Mercedes Benz command auto, alone, desolate, and sobbing is perhaps one of the saddest yet truest depictions of a \"spy\\'s\" lot in life. Only the emotional pain presented by Richard Burton in the Spy Who Came in from the Cold comes close. Fraulein Doktor is a far deeper film than one may realize upon a singular viewing. I only wish that its producers would see fit to release it on DVD so that those who have never experienced it can, and those who have seen it can again (perhaps again and again)enjoy this exceptional motion picture.'\n",
            " b'First off, let me say I have wanted to see this movie for about a year now because I knew Angelina Jolie was in it and I love her. But my love for her has nothing to do with my opinion of the movie. Anyhow, no video stores carried it but low and behold the local library did. I watched it and absolutely loved it. Yes there were Italian stereotypes but it was done well and funny. It was not degrading in any way.<br /><br />Every actor and actress did a superb job. I laughed very hard at the sexual humor. Overall, I think this movie is well worth seeing if you can find it. It is adorable and just plain fun to watch. I rarely rank movies as a 10 but I give this one a 10!!!<br /><br />Go find it and watch it!'\n",
            " b\"I happened to catch this movie on cable one afternoon. I have to admit that I've never been a big baseball fan, but I can sometimes get into a good sports-related movie. What I found more interesting was the depiction of the foster family system. As a therapist who has seen both the good and the bad of the community mental health and foster system, I though it was rather refreshing to see a movie that showed both the ups and downs of this system: people jumping from family to family, biological parents not always taking an active involvement, and transitions that can be but heart-wrenching and heart-melting. Joseph Gordon-Levitt and Danny Glover are the anchor of this film, and both bring very believable performances. Maybe it was just my emotional state, but I did find myself shedding a tear at the end of the film.\"\n",
            " b\"It is so gratifying to see one great piece of art converted into another without distortion or contrivance. I had no guess as to how such an extraordinary piece of literature could be recreated as a film worth seeing. If you loved Bulgakov's book you would be, understandably, afraid of seeing some misguided interpretation done more for the sake of an art-film project than for actually bringing the story's deeper meaning to the screen. There are a couple examples of this with the Master and Margarita. As complex and far-fetched as the story is, the movie leaves out nothing. It is as if the filmmaker read Bulgakov's work the same way an orchestral conductor reads a score--with not a note missed. Why can't we find such talent here in the U.S. ? So now my favorite book and movie have the same title.\"\n",
            " b'i can\\'t believe that NONE of the official reviews for this movie warn people that it contains two quite upsetting sexual assault scenes. It\\'s as though our culture accepts this kind of behavior as simply sexual but not violent. My biggest problem with the movie is that it doesn\\'t seem to condemn these assaults - as in, the woman who is repeatedly assaulted and pressured never holds the men accountable for their actions, and neither does anyone else. One man is stopped from completing the assault when someone throws a dagger at him, but he is reprimanded only with \"you cannot force a woman to love you\" rather than \"you should never force a woman sexually, you jerk\"... From a woman\\'s point of view, the movie is a let down. It sort of \"throws a bone\" to women in letting them be both skilled fighters and leaders, but the movie is much more defined by the romance - which is characterized by the notion that human sexuality must involve an imbalance of power, with men dominating the woman they love. This amazing martial arts fighter doesn\\'t use any of her fighting skills to try to fend off her attackers. She never even makes them apologize - rather, SHE seems apologetic. Overall, a depressing and upsetting movie, with some great cinematography and some cool fight scenes, but not as good as Hero by a long shot.'\n",
            " b'There are some nice shots in this film, it catches some of the landscapes with such a beautiful light, in fact the cinematography is probably it\\'s best asset.<br /><br />But it\\'s basically more of a made for TV movie, and although it has a lot of twists and turns in the plot, which keeps it quite interesting viewing, there are no subtitles and key plot developments are unveiled in Spanish, so non Spanish speakers will be left a little lost.<br /><br />I had it as a Xmas gift, as it\\'s a family trait to work through the films of a actor we find talented, and Matthew Mconaughey was just awesome in \"A Time to kill\" , and the \"The Newton Boys \" so I expressed I wanted to see more of his work.<br /><br />However although it says on the DVD box it is a Matthew Mconaughey film and uses this as a marketing ploy, he has a few lines and is on screen for not very minutes at the end of the film, he is basically an extra and he doesn\\'t exactly light up the screen while he is on, so die hard fans, really not worth it from that point of view.<br /><br />The films star though, Patrick McGaw is great though and very easy on the eye, and his character is just so nice and kind and caring, a true saint of a guy, he\\'d be well written into a ROM com.<br /><br />So for true Mcconaughey acting brilliance of the ones I\\'ve seen, I\\'d recommend, \"A Time to kill\" , \"The Newton Boys \" \"Frailty\", \"How to Lose a Guy in 10 Days\", \"Edtv\" and \"Amistad\" and avoid too \"Larger Than Life\" and \"Angels in the Outfield\" unless you feel like a kids film or have kids around as neither of these are indicative of his talent, but are quite amusing films for children, again MM is really nothing more that a supporting artist with just a few if any lines.<br /><br />As for Scorpion Springit\\'s not a bad film but it also isn\\'t screen stealing either.'\n",
            " b\"I watched this movie after watching Practical Magic, and the older film was far superior. I liked the way the lighting, makeup, and costumes changed as Gillian changed in the story. Jimmy Stewart's mannerisms didn't do a lot for me in this film, but I suppose they did serve to highlight the reserve of Gillian's character. I was also struck by Nicky's and Gillian's mannerisms--it was as if the director wanted him to appear effeminate and Gillian to appear masculine. The gestures Nicky makes when he's showing Redlich his powers especially struck me. I've never thought of warlocks as being effeminate, so it was an interesting way of contrasting those characters.\"\n",
            " b\"The plot is about the death of little children. Hopper is the one who has to investigate the killings. During the movie it appears that he has some troubles with his daughter. In the end the serial killer get caught. That's it. But before you find out who dunnit, you have to see some terrible acting by all of the actors. It is unbelievable how bad these actors are, including Hopper. I could go on like this but that to much of a waste of my time. Just don't watch the movie. I've warned you.\"\n",
            " b\"Back in the days before the Toxic Avenger, the low-camp kings at Troma Films tried to take the high (OK, somewhat-less-low) road of producing straight slasher pics. I'd like to think that viewing the results here is what convinced them to give up all pretension and go for self-conscious parody.<br /><br />Splatter University is another film for the masochists in the audience. As it meanders about through two separate casts and innumerable pointless subplots, it actually becomes painful to watch. Let's see if I can summarize.<br /><br />After learning that a dangerous psychopath has escaped from a local hospital, the action moves to a Catholic university (I don't recall the name, but in honor of the title, let's call it St. Splatter). The students are listless and sullen, and argue pettily with each other, slackers ahead of their time. Meanwhile, the new professor, Julie Parker, proves utterly incompetent at her job. The kids deal with relationships, infidelity, unwanted pregnancies, lecherous priests, and how to avoid doing any work in class; Julie deals with a creepy boyfriend, the inflexible administration at St. Splatter, counseling unwed mothers, and the blank, expressionless looks of her students. None of it means a darn thing or gets resolved in any meaningful way. Oh, and every once in a while, a POV shot comes along and stabs one of the girls to death, but don't hold your breath waiting for it. There's a Red Herring Killer, and then a sadly anticlimactic confrontation with the Real Killer, then it's back to the asylum and roll credits.<br /><br />The slow pace and numerous inane subplots seem almost calculated to produce a mounting sense of frustration in the viewer, which is helped along by choppy editing, coffee-can sound quality, and dialog that just doesn't make any sense. And the most agonizing thing about this movie is the killer's fixation on women - the men in this movie are just so deserving. I'd've paid good money to see someone off the jerk with the pregnant girlfriend, or the lunkhead Lothario who was fooling around with his girlfriend's roommate, or any of the creepy priests. There ain't no justice.\"\n",
            " b'It\\'s only 2 episodes into a 5 part drama, but I can already state that this is one of the best things I\\'ve ever seen. That\\'s on TV, silver screen or even in real life.<br /><br />As a writer, it\\'s so good it\\'s almost demoralising! As a viewer it\\'s so entertaining that I\\'m annoyed the episodes are over a fortnight instead of Monday to Friday. It\\'s clear that all these negatives are actually positives.<br /><br />I\\'m a modern guy who previously turned over from TV dramas. In comparison to movies, TV dramas always seemed to be dated, quite tame, and well, generally boring! \"Five Days\" has really brought TV drama into the 21st Century, so for me at least, it\\'s mind changing. Go watch it.'\n",
            " b'Alone in The Dark is one of my favorite role-playing-games of all time. I remember spending whole nights facing the PC screen, trying to escape that mansion and actually being startled at times when monsters came surprisingly charging in. Now, mind you - I am weary of \"computer-game-generated\" movies. I don\\'t remember a single success story in this new Hollywood genre, although some are entertaining enough to be watchable. And yet, I am such a big fan of the game that I couldn\\'t resist. My rationale was that if the movie had a plot that so much as resembled the game\\'s, it would be OK. <br /><br />Man, those were 90 minutes (which seemed like 300) of my life that I\\'ll never get back. If I had that chance, I would have gladly spent them rearranging my sock drawer instead. This isn\\'t even in the \"so bad it\\'s funny\" category. You would think even Christian Slater had a bit more sense than joining this stink bomb. Now, Tara Reid... I\\'m not complaining about her presence. However, if the purpose of putting this chick in a starring role is to have a sex scene, - which I totally understand and support (hey, I\\'m a guy!) - I\\'ve seen more of her body on press conferences.<br /><br />There is no plot to speak of. Won\\'t waste your time pitching it to you. The credibility of the story sinks below \\'I did not have sex with Ms. Lewinski\\'. The acting is but a few notches above \\'Street Fighter\\', which, by the way, being one of the worst movies I\\'ve seen, I would recommend OVER this one.<br /><br />Kids, I recommend the Video Game. It has far better story, acting and much more thrills. As for the movie, here\\'s a spoiler - it STINKS! Wait for the porno version.'\n",
            " b'Early film directed by D.W. Griffith; it features a gloriously happy King (Arthur V. Johnson) and his Queen (Marion Leonard) - but, wait! When the King leaves the scene, his Queen makes music with the palace\\'s Minstrel (Henry B. Walthall). When the King discovers the lovers, he decides to enact a horrific Edgar Allen Poe-type revenge. It\\'s difficult to believe the lovers can\\'t hear those plotting against them; although the actors are trying to look alternately noisy (the lovers) and quiet (the cement mixers). The sets make \"The Sealed Room\" look very staged. The performances are okay, and the story is easy to follow. <br /><br />*** The Sealed Room (9/2/09) D.W. Griffith ~ Arthur V. Johnson, Henry B. Walthall, Marion Leonard'\n",
            " b'i thought this movie was wonderfully plotted it made me confused and my cousin who watched it with me.to tell the truth i think that the younger kevin dillon was hot.hahahaha...but i also thought the girl was stupid to go along with the cop and that was wrong what he said to her before his death\"i was inside you\".i think that\\'s what she gets for doing what she did with him and how is he going to tell her that she\\'s too young when he never cared how old the other girls were.?now i don\\'t think i myself could ever trust a cop like that.but to tell the truth it was pretty obvious it was him even if he was wanting to become a cop i would still be suspicious of him either way.and that was funny when she sprayed him in the eye in the store.hahahahaha.she was still stupid for going into the warehouse again by herself and so was the cop who died HELLO!! it\\'s called back-up.sometimes these movies make me mad when people act stupid and do stupid things.but that\\'s what i think an thought about the movie.'\n",
            " b\"I enjoyed watching Cliffhanger, at the beginning when that woman (Sarah) was full of terror when she was slipping, i thought that was a terrifying scene as i would think that when you see that see, your nerves in your body get to you because it makes you get full of fright and your heart beats faster. I did like watching Cliffhanger, i think Silvestar Stallone is a great actor and i think he'll be known as playing Rambo and Rocky.\"\n",
            " b\"This is the movie for those who believe cinema is the seventh art, not an entertainment business. Lars von Trier creates a noir atmosphere of post-war Germany utterly captivating. You get absorbed into the dream and you're let go only at the end credits. The plot necessarily comes second, but it still is a thrilling story with tough issues being raised. Just wonderful.\"\n",
            " b\"This film is just another distortion, among many distortions, on the so-called 'sins of consumerism'. Please note that 'Reverend Billy', an actor (Bill Talen), is nothing more than a bureaucrat against the 'sins of consumerism'. We might want to ask are questions, like: What does 'Reverend Billy' do for a living? How does he make his money? Does he make his living off his 'tax-deductible' organization? How does the Internal Revenue justify this as a 'tax-deductible' church or organization? <br /><br />Everyone knows that Christmas is commercialized, but it affords one day out of a whole year in which people have an opportunity to be charitable, and allows a significant number of people to spend time with their families, friends, or extended families. Everyone is not charitable. Everyone does not spend time with their families, friends, or extended families. But, holidays and vacation time give people that chance and opportunity. Yes, America does have more than its share of problems--but, with perseverance, Americans have and always make it through great difficulties. And, even in times of strife, America has proved itself to be the greatest country in the world. That happens when Americans pull together and unite, rather than to separate and divide. Yes, there are problems with corporations and monopolies, but it will take Americans to bring back the small businesses, along with the ethics to responsibly care for people living in our individual communities. Yes, globalization has brought us its share of problems, but it will take Americans to bring production back to America. Americans and the U.S. government need to learn how to stay on a budget, no matter how large or small it may be, and we must stop our dependence on credit. Our over-reliance on credit will make, and keep us poor, from the cradle to the grave. It is important to buy--but, if we buy less, we will rely less on credit. And, if we are able to save, even a small amount of money, we will have money for a rainy day. Not to say that, as Americans, we will gain an equal share of wealth. Wealth is not guaranteed, and has never been guaranteed. But, stratification teaches us that only a small percentage of Americans hold most of America's wealth. There is a good proximity that you or I can reach the level of the upper, middle class. And, who knows what can happen from there?!? Be positive, work hard--and, at the very least, you and I will be able to reach at least some (if not all) of our dreams. In life, nothing is guaranteed, but we always have that something to reach for. And, if you or I don't have dreams, we might as well be dead. In America, there is always room for plenty of hopes and dreams. As individuals, we are a part of the pack, but we always can become the leader of the pack.<br /><br />It has always been my experience that churches and religion do offer nothing more than additional distortions, but I pay dignity and give respect to people with other beliefs, values, and perspectives. But, as far as the distortions expressed, within this film, I do not have any faith in such beliefs, values, and perspectives. I rank this film with a 1 out of 10--but, in all honesty and truth, this film deserves a zero. This film has no integrity, and I cannot recommend it.\"\n",
            " b'This movie is very important because suggested me this consideration: sometimes you can wish to be sick ... sometimes you can wish to have a syndrome ... sometimes, for example, you can wish have Goldfield Syndrome... that way you\\'d not remember this boring movie ... and above all you\\'d not remember Adam \"superfluos\" Sandler... sometimes, simply, you can wish... have rented another movie...<br /><br />My vote? 3 out of 10. My suggestion? If you are neither a fan of boring romantic comedies or Adam Sandler (...it\\'s a joke don\\'t exist Adam Sandler\\'s fan...I want to hope it), save yourself... Someone to save? Drew Barrymore. ... perhaps.'\n",
            " b\"This is possibly one of the worst movies I have ever seen. I don't care what the critics say, it's bad. I think the problem is with Kundera's novel. It's not that it's unfilmable; it's just that like 99% of his work, it's pretentious and overdrawn. He seems to be enamored with himself,his characters come off as navel-gazing, and his novels as a whole are misogynistic. I have read many of his works (even his Socialist Realist poetry. That was truly awful) -- I just don't understand what the fuss is about. Characteristics (like the self-absorption) in his novels make for infuriating reading. In a movie, all the things that I dislike about Kundera were magnified. Maybe I just missed something, but I don't think so. On a side note, I cannot believe that this is a Criterion Collection DVD. No way is this movie THAT essential.\"\n",
            " b\"I can't say much about this film. I think it speaks for itself (as do the current ratings on here). I rented this about two years ago and I totally regretted it. I even /tried/ to like it by watching it twice, but I just couldn't. I can safely say that I have absolutely no desire to see this waste of time ever, ever again. And I'm not one to trash a movie, but I truly believe this was awful. It wasn't even funny in the slightest. The only bits I enjoyed were the few scenes with Christopher Walken in them. I think this film ruined both Jack Black and Ben Stiller for me. All I can think of when I see one of their films now-a-days is this terrible movie, and it reminds me not to waste my money. Amy Poehler is so very annoying, too.<br /><br />Overall, well, I think you get my point. The stars are for Walken, by the way.\"\n",
            " b'Like a latter day Ayn Rand, Bigelow is la major muy macho in her depiction in the film of a few tough American hombres stuck in Iraq defusing roadside bombs set by the ruthless, relentless, child-killing Arab terrorists. As Bigelow posits the Iraq war as the backdrop of the grand stage of human drama, one veteran bomb expert gets blown up and another shows up to replace him in the dusty, hot, ugly rubble that is Iraq, and a new hero is born.<br /><br />The new guy is what John Hershey described in his book, and later the movie, The War Lover, as a sadistic wingnut who actually isn\\'t fit for civilian life, and requires the stimulation of war to sublimate and suppress his errant sexual desires. The war lover can only fully function in war, peacetime suffocates him. While Hershey chastised the war lover, (played in the film by Steve McQueen in one of his greatest roles) Bigelow glorifies him. The army needs war lovers, they are the bulwark of defense against our enemies. We can\\'t handle the truth, that it is war lovers who are the best soldiers, the toughest men. According to the unironic Bigelow, regular men are pussies, the war lover is a special breed, the last of the cowboys. So what if he wants to bare-back his men, or fondle an Iraqi boy? He is a throwback to the sex-and-death cult of war. In war, sex is a thankless, loveless, don\\'t-ask, don\\'t-tell kind of male bonding. Bigelow has no opinion on this; she just limits the options of masculinity in this ham-fisted attempt at realism. Only a war-lover can win the moral struggle between right and wrong, between American innocence and Arab perfidy. Bigelow disguises her racism and arrogance behind the ingenuous facade of journalism. She\\'s just another gung-ho yahoo depicting a brutal war against civilians as a moral triumph of the spirit.<br /><br />On the political front, Bigelow returns to the western genre and its relentless clich\\xc3\\xa9s again and again, ad nauseam: the wonderful world of the open frontier, which happens to be some one else\\'s country. (\"You can shoot people here\" says a soldier ); the tough but human black guy companion, the soldier with a premonition of death, the gruff, possibly crazy commanding officer, the college-educated fool who tries to befriend the enemy. You name it, Bigelow resurrects it.<br /><br />The man-boy love is palpable in scenes with the cute Arab boy who befriends the war lover, but Bigelow plays it straight; she doesn\\'t consummate the sex, just sanitizes it. What Bigelow really wants to show us is the ugly, sneering face of the Arab enemy. Any Iraqi who isn\\'t pure evil is either demented, hostile or up to no good, anyway. They all deserve to die for their impudence, and many of them do in this glib gore-fest film. The Iraqi women are all hysterical, they only make their presence known by screaming. They could be male stunt men in drag for all I know, you never see their faces. There is no female presence at all on base or in battle, although female casualty rates in Iraq would certainly disprove this.<br /><br />Bigelow goes through all the motions one by one. She glorifies war, she canonizes the sadist nut-case hero. The cowboys, surrounded by the subhuman Indians, prove their mettle by doing God\\'s work and subduing the wretched terrorist-infested hellhole with sheer bravado and suicidal mania. Toward the end, I felt like rooting for the Indians. In Bigelow\\'s world, though, no mercy or understanding ever makes it through. The Iraqis are dehumanized par excellence. The slaughter of civilians is just the dramatic backdrop to our hero\\'s psycho sexual struggle. Every U.S, bullet finds its mark. You have to love the guy, the war lover. It\\'s just his way, he is the true hero. He\\'s just a guy trying to get things done the hard way, and so what if he lusts for boy tang on the side.'], shape=(32,), dtype=string)\n",
            "\n",
            "tf.Tensor([1 0 0 1 1 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 0 0 0 0], shape=(32,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_sentences(input_data):\n",
        "    '''\n",
        "    Input: raw reviews\n",
        "    output: standardized reviews\n",
        "    '''\n",
        "    output=tf.strings.lower(input_data)\n",
        "    outputs=tf.strings.regex_replace(output,\"<[^>]+>\",\"\")\n",
        "    outputs=tf.strings.regex_replace(output,\"<[%s]\"%re.escape(string.punctuation),\" \")\n",
        "    outputs=tf.strings.regex_replace(output,\"  \",\" \")\n",
        "    \n",
        "    return output"
      ],
      "metadata": {
        "id": "KMIBL9qDVZ5y"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def preprocess_sentences(input_data):\n",
        "\n",
        "#      output = tf.strings.lower(input_data)\n",
        "#      output = tf.strings.regex_replace(output, \"<[^>]+>\",\"\")\n",
        "#      output = tf.strings.regex_replace(output,'[%s]' %re.escape(string.punctuation), \"  \")\n",
        "#      output = tf.strings.regex_replace(output, '  ',\" \"  )\n",
        "#      lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "#      output = tf.strings.join([lemmatizer.lemmatize(str(word)[12:-26], pos = \"a\") for word in tf.strings.split(output)], separator = \" \")\n",
        "#      return output\n",
        "# preprocess_sentences(\"I kind of consider myself as the #1 fan of Hidden Frontier\")\n"
      ],
      "metadata": {
        "id": "RbKsA4WYKC0N"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE=2000\n",
        "SEQUENCE_LENGTH=100\n",
        "vectorize_layer=TextVectorization(\n",
        "    standardize=preprocess_sentences,\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=SEQUENCE_LENGTH,\n",
        ")\n",
        "training_data=train_dataset.map(lambda x,y:x)### inputsxandyand outputsx\n",
        "vectorize_layer.adapt(training_data)### Adapt the vectorize Layer to the training data"
      ],
      "metadata": {
        "id": "1_UHiFcc9A8K"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorizer(review, label):\n",
        "  return tf.one_hot(vectorize_layer(review), depth = VOCAB_SIZE), label\n"
      ],
      "metadata": {
        "id": "LeyD0T3p3seD"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.map(vectorizer)\n",
        "val_dataset = val_dataset.map(vectorizer)"
      ],
      "metadata": {
        "id": "zB7o5OOz4ePe"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x , y in train_dataset.take(1):\n",
        "  print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLHlkkDM4yOs",
        "outputId": "90456095-173a-43d8-bc9c-cc043e9143f3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0 1 1 0 0 1 1 0 1 1 0 1 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0], shape=(32,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling\n"
      ],
      "metadata": {
        "id": "9kQ87P7kYH80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNCell(tf.keras.layers.Layer):\n",
        "  def __init__(self, units = 4, hidden_size = 7,):\n",
        "    super(RNNCell, self).__init__()\n",
        "\n",
        "    self.units = units\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    print(input_shape)\n",
        "\n",
        "    self.w_hh = self.add_weight(\n",
        "        shape = (self.hidden_size, self.hidden_size),\n",
        "        initializer = \"random_normal\",\n",
        "        trainable = True,\n",
        "    )\n",
        "    self.w_hx = self.add_weight(\n",
        "        shape = (input_shape[-1], self.hidden_size),\n",
        "        initializer = \"random_normal\",\n",
        "        trainable = True,\n",
        "    )\n",
        "    self.w_yh = self.add_weight(\n",
        "        shape = (self.hidden_size, self.units),\n",
        "        initializer = \"random_normal\",\n",
        "        trainable = True,\n",
        "    )\n",
        "\n",
        "    self.b_h = self.add_weight(\n",
        "        shape = (self.hidden_size,),\n",
        "        initializer = \"random_normal\",\n",
        "        trainable = True,\n",
        "    )\n",
        "    \n",
        "    self.b_y = self.add_weight(\n",
        "        shape = (self.units,),\n",
        "        initializer = \"random_normal\",\n",
        "        trainable = True,\n",
        "    )\n",
        "\n",
        "  def call(self, inputs, h_prev = None):\n",
        "    if(h_prev == None):\n",
        "      h_prev = tf.zeros([inputs.shape[0], self.hidden_size])\n",
        "    h = tf.nn.tanh(tf.matmul(h_prev, self.w_hh) + tf.matmul(inputs, self.w_hx) + self.b_h)\n",
        "    y = tf.nn.tanh(tf.matmul(h, self.w_yh) + self.b_y)\n",
        "    \n",
        "    return tf.constant(h), tf.constant(y)\n"
      ],
      "metadata": {
        "id": "jjbwN2KIW57u"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = tf.zeros([8,  2000])\n",
        "layer = RNNCell()\n",
        "h,y = layer(input)\n",
        "h.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca2w_Q25dXla",
        "outputId": "53049cbb-de52-4bb3-a3b8-b43b0ecabdc1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8, 2000)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([8, 7]), TensorShape([8, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(tf.keras.layers.Layer):\n",
        "  def __init__(self, units, ):\n",
        "    super(RNN, self).__init__()\n",
        "    self.rnn = RNNCell(units)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    output = []\n",
        "\n",
        "    h,y = self.rnn(input[:,0,:])\n",
        "    output.append(y)\n",
        "\n",
        "    for i in range(1, input.shape[-2]):\n",
        "      h, y = self.rnn(input[:,i,:], h)\n",
        "      output.append(y)\n",
        "    shape = np.array(output).shape\n",
        "    return tf.reshape(output,[ shape[1], shape[0], shape[2]])\n"
      ],
      "metadata": {
        "id": "NEo_rRYWictg"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = tf.zeros([8, 100,2000])\n",
        "layer = RNN(4)\n",
        "output = layer(input)\n",
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLnNfQ0mqHsX",
        "outputId": "6b824f75-ad7d-4338-9d29-4bb360734a86"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8, 2000)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([8, 100, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = tf.zeros([8, 100,2000])\n",
        "layer = SimpleRNN(4, activation = 'tanh', use_bias = True, return_sequences=False, name = \"layer1\")\n",
        "\n",
        "output = layer(input)\n",
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPjVLsoBqsQL",
        "outputId": "7f241fcb-e40d-4c9c-c39d-0fde35c7016d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([8, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " input = tf.keras.layers.Input(shape = (SEQUENCE_LENGTH,))\n",
        " embedding_size = 256\n",
        "\n",
        " model = tf.keras.models.Sequential([\n",
        "                                     input,\n",
        "                                     tf.keras.layers.Embedding(VOCAB_SIZE, embedding_size),\n",
        "                                     SimpleRNN(4, activation = 'tanh', use_bias = True, return_sequences=True, name = \"layer1\"),\n",
        "                                     Dense(1, activation = \"relu\", name=\"layer2\"),\n",
        "                                     Reshape((SEQUENCE_LENGTH,), name = \"layer3\"),\n",
        "                                     Dense(1, activation = \"sigmoid\", name = \"layer4\")\n",
        " ])\n",
        " model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEBU1Cd4rN27",
        "outputId": "98061b5f-005a-44b7-d27a-48e98df01694"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 100, 256)          512000    \n",
            "                                                                 \n",
            " layer1 (SimpleRNN)          (None, 100, 4)            1044      \n",
            "                                                                 \n",
            " layer2 (Dense)              (None, 100, 1)            5         \n",
            "                                                                 \n",
            " layer3 (Reshape)            (None, 100)               0         \n",
            "                                                                 \n",
            " layer4 (Dense)              (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 513,150\n",
            "Trainable params: 513,150\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Validation and Testing"
      ],
      "metadata": {
        "id": "0s4r2QZ70-cY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 1e-4\n",
        "EPOCH = 50\n",
        "\n",
        "model.compile(\n",
        "    loss = tf.keras.losses.BinaryCrossentropy(from_logits = True),\n",
        "    optimizer = tf.keras.optimizers.Adam(lr = LR,),\n",
        "    metrics = [\"accuracy\"],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcoAyUDKuPvz",
        "outputId": "7c135cc5-1d3c-4b35-81e9-7d1bcffd2ace"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EC9bZL6n_tx-"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_filepath  = \"basic_rnn.hdf5\"\n",
        "\n",
        "#checkpoint_filepath=\"imdb/basic_rnn.hdf5\"\n",
        "callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "   filepath=checkpoint_filepath,### WHERE BEST WEIGHTS ARE STORED\n",
        "    save_weights_only=True,\n",
        "   monitor=\"loss\",\n",
        "   mode='min',\n",
        "    save_best_only=True)\n",
        "#Train model on dataset\n",
        "history=model.fit(train_dataset,validation_data=val_dataset,verbose=1,epochs=EPOCH,callbacks=[callback])#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcKp-Yqv1s6s",
        "outputId": "41ab45dc-88ce-45b6-ec33-b36c5e3d81af"
      },
      "execution_count": 43,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 79s 100ms/step - loss: 0.6943 - accuracy: 0.5016 - val_loss: 0.6931 - val_accuracy: 0.4972\n",
            "Epoch 2/50\n",
            "782/782 [==============================] - 78s 99ms/step - loss: 0.6929 - accuracy: 0.5111 - val_loss: 0.6930 - val_accuracy: 0.5020\n",
            "Epoch 3/50\n",
            "782/782 [==============================] - 79s 101ms/step - loss: 0.6920 - accuracy: 0.5238 - val_loss: 0.6929 - val_accuracy: 0.5062\n",
            "Epoch 4/50\n",
            "782/782 [==============================] - 78s 100ms/step - loss: 0.6907 - accuracy: 0.5358 - val_loss: 0.6926 - val_accuracy: 0.5113\n",
            "Epoch 5/50\n",
            "782/782 [==============================] - 78s 99ms/step - loss: 0.6849 - accuracy: 0.5412 - val_loss: 0.6812 - val_accuracy: 0.5510\n",
            "Epoch 6/50\n",
            "782/782 [==============================] - 79s 101ms/step - loss: 0.6501 - accuracy: 0.6271 - val_loss: 0.6419 - val_accuracy: 0.6544\n",
            "Epoch 7/50\n",
            "782/782 [==============================] - 78s 99ms/step - loss: 0.6094 - accuracy: 0.7084 - val_loss: 0.6176 - val_accuracy: 0.7038\n",
            "Epoch 8/50\n",
            "782/782 [==============================] - 78s 100ms/step - loss: 0.5781 - accuracy: 0.7454 - val_loss: 0.5931 - val_accuracy: 0.7322\n",
            "Epoch 9/50\n",
            "782/782 [==============================] - 78s 100ms/step - loss: 0.5528 - accuracy: 0.7661 - val_loss: 0.5751 - val_accuracy: 0.7406\n",
            "Epoch 10/50\n",
            "782/782 [==============================] - 77s 99ms/step - loss: 0.5304 - accuracy: 0.7799 - val_loss: 0.5620 - val_accuracy: 0.7478\n",
            "Epoch 11/50\n",
            "782/782 [==============================] - 78s 100ms/step - loss: 0.5091 - accuracy: 0.7923 - val_loss: 0.5517 - val_accuracy: 0.7529\n",
            "Epoch 12/50\n",
            "782/782 [==============================] - 78s 99ms/step - loss: 0.4886 - accuracy: 0.8006 - val_loss: 0.5434 - val_accuracy: 0.7550\n",
            "Epoch 13/50\n",
            "782/782 [==============================] - 77s 99ms/step - loss: 0.4680 - accuracy: 0.8082 - val_loss: 0.5426 - val_accuracy: 0.7573\n",
            "Epoch 14/50\n",
            "782/782 [==============================] - 78s 100ms/step - loss: 0.4496 - accuracy: 0.8146 - val_loss: 0.5391 - val_accuracy: 0.7592\n",
            "Epoch 15/50\n",
            "782/782 [==============================] - 77s 99ms/step - loss: 0.4343 - accuracy: 0.8204 - val_loss: 0.5373 - val_accuracy: 0.7594\n",
            "Epoch 16/50\n",
            "782/782 [==============================] - 76s 97ms/step - loss: 0.4220 - accuracy: 0.8261 - val_loss: 0.5370 - val_accuracy: 0.7566\n",
            "Epoch 17/50\n",
            "782/782 [==============================] - 77s 98ms/step - loss: 0.4121 - accuracy: 0.8292 - val_loss: 0.5455 - val_accuracy: 0.7614\n",
            "Epoch 18/50\n",
            "782/782 [==============================] - 78s 99ms/step - loss: 0.4017 - accuracy: 0.8356 - val_loss: 0.5528 - val_accuracy: 0.7614\n",
            "Epoch 19/50\n",
            "782/782 [==============================] - 77s 99ms/step - loss: 0.3932 - accuracy: 0.8406 - val_loss: 0.5468 - val_accuracy: 0.7586\n",
            "Epoch 20/50\n",
            "782/782 [==============================] - 77s 99ms/step - loss: 0.3854 - accuracy: 0.8448 - val_loss: 0.5495 - val_accuracy: 0.7586\n",
            "Epoch 21/50\n",
            "782/782 [==============================] - 77s 98ms/step - loss: 0.3784 - accuracy: 0.8479 - val_loss: 0.5565 - val_accuracy: 0.7597\n",
            "Epoch 22/50\n",
            "782/782 [==============================] - 78s 99ms/step - loss: 0.3726 - accuracy: 0.8514 - val_loss: 0.5636 - val_accuracy: 0.7610\n",
            "Epoch 23/50\n",
            "782/782 [==============================] - 81s 103ms/step - loss: 0.3661 - accuracy: 0.8546 - val_loss: 0.5621 - val_accuracy: 0.7602\n",
            "Epoch 24/50\n",
            "782/782 [==============================] - 78s 99ms/step - loss: 0.3604 - accuracy: 0.8581 - val_loss: 0.5638 - val_accuracy: 0.7590\n",
            "Epoch 25/50\n",
            "782/782 [==============================] - 91s 116ms/step - loss: 0.3553 - accuracy: 0.8608 - val_loss: 0.5771 - val_accuracy: 0.7600\n",
            "Epoch 26/50\n",
            "782/782 [==============================] - 78s 100ms/step - loss: 0.3498 - accuracy: 0.8637 - val_loss: 0.5703 - val_accuracy: 0.7576\n",
            "Epoch 27/50\n",
            "782/782 [==============================] - 77s 98ms/step - loss: 0.3461 - accuracy: 0.8659 - val_loss: 0.5753 - val_accuracy: 0.7580\n",
            "Epoch 28/50\n",
            "782/782 [==============================] - 78s 100ms/step - loss: 0.3404 - accuracy: 0.8688 - val_loss: 0.5887 - val_accuracy: 0.7581\n",
            "Epoch 29/50\n",
            "782/782 [==============================] - 78s 100ms/step - loss: 0.3370 - accuracy: 0.8699 - val_loss: 0.5842 - val_accuracy: 0.7556\n",
            "Epoch 30/50\n",
            "782/782 [==============================] - 79s 101ms/step - loss: 0.3313 - accuracy: 0.8727 - val_loss: 0.5897 - val_accuracy: 0.7554\n",
            "Epoch 31/50\n",
            "782/782 [==============================] - 80s 102ms/step - loss: 0.3279 - accuracy: 0.8730 - val_loss: 0.6062 - val_accuracy: 0.7584\n",
            "Epoch 32/50\n",
            "782/782 [==============================] - 80s 102ms/step - loss: 0.3236 - accuracy: 0.8766 - val_loss: 0.6150 - val_accuracy: 0.7580\n",
            "Epoch 33/50\n",
            "782/782 [==============================] - 79s 101ms/step - loss: 0.3205 - accuracy: 0.8776 - val_loss: 0.6065 - val_accuracy: 0.7576\n",
            "Epoch 34/50\n",
            "782/782 [==============================] - 81s 103ms/step - loss: 0.3146 - accuracy: 0.8815 - val_loss: 0.6119 - val_accuracy: 0.7553\n",
            "Epoch 35/50\n",
            "782/782 [==============================] - 80s 102ms/step - loss: 0.3116 - accuracy: 0.8821 - val_loss: 0.6359 - val_accuracy: 0.7559\n",
            "Epoch 36/50\n",
            "782/782 [==============================] - 80s 102ms/step - loss: 0.3078 - accuracy: 0.8840 - val_loss: 0.6270 - val_accuracy: 0.7568\n",
            "Epoch 37/50\n",
            "782/782 [==============================] - 80s 103ms/step - loss: 0.3040 - accuracy: 0.8857 - val_loss: 0.6306 - val_accuracy: 0.7558\n",
            "Epoch 38/50\n",
            "782/782 [==============================] - 80s 102ms/step - loss: 0.3009 - accuracy: 0.8869 - val_loss: 0.6353 - val_accuracy: 0.7558\n",
            "Epoch 39/50\n",
            "782/782 [==============================] - 80s 102ms/step - loss: 0.2967 - accuracy: 0.8906 - val_loss: 0.6352 - val_accuracy: 0.7527\n",
            "Epoch 40/50\n",
            "782/782 [==============================] - 80s 103ms/step - loss: 0.2925 - accuracy: 0.8920 - val_loss: 0.6388 - val_accuracy: 0.7502\n",
            "Epoch 41/50\n",
            "782/782 [==============================] - 79s 101ms/step - loss: 0.2891 - accuracy: 0.8944 - val_loss: 0.6495 - val_accuracy: 0.7519\n",
            "Epoch 42/50\n",
            "782/782 [==============================] - 80s 102ms/step - loss: 0.2869 - accuracy: 0.8941 - val_loss: 0.6565 - val_accuracy: 0.7518\n",
            "Epoch 43/50\n",
            "782/782 [==============================] - 80s 102ms/step - loss: 0.2839 - accuracy: 0.8953 - val_loss: 0.6530 - val_accuracy: 0.7497\n",
            "Epoch 44/50\n",
            "782/782 [==============================] - 79s 101ms/step - loss: 0.2791 - accuracy: 0.8979 - val_loss: 0.6675 - val_accuracy: 0.7510\n",
            "Epoch 45/50\n",
            "782/782 [==============================] - 80s 102ms/step - loss: 0.2773 - accuracy: 0.9003 - val_loss: 0.6699 - val_accuracy: 0.7494\n",
            "Epoch 46/50\n",
            "782/782 [==============================] - 80s 102ms/step - loss: 0.2737 - accuracy: 0.9001 - val_loss: 0.6802 - val_accuracy: 0.7500\n",
            "Epoch 47/50\n",
            "782/782 [==============================] - 79s 101ms/step - loss: 0.2717 - accuracy: 0.9021 - val_loss: 0.6825 - val_accuracy: 0.7489\n",
            "Epoch 48/50\n",
            "782/782 [==============================] - 80s 102ms/step - loss: 0.2685 - accuracy: 0.9023 - val_loss: 0.6971 - val_accuracy: 0.7483\n",
            "Epoch 49/50\n",
            "782/782 [==============================] - 79s 101ms/step - loss: 0.2655 - accuracy: 0.9049 - val_loss: 0.7035 - val_accuracy: 0.7487\n",
            "Epoch 50/50\n",
            "782/782 [==============================] - 79s 101ms/step - loss: 0.2626 - accuracy: 0.9057 - val_loss: 0.7100 - val_accuracy: 0.7496\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history[\"loss\"][:])\n",
        "plt.plot(history.history[\"val_loss\"][:])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','val'], loc = 'upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "pVD9pxjn_wEs",
        "outputId": "41cb5361-b6be-48ba-8561-19a21e31fe7d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history[\"accuracy\"][:])\n",
        "plt.plot(history.history[\"val_accuracy\"][:])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','val'], loc = 'upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gMfkKzs-19cw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "fca9e5f8-057c-486b-812d-c4e7254dcd06"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = tf.data.Dataset.from_tensor_slices([[\"i love it\"],[\"i dont like movie\"]\n",
        "])"
      ],
      "metadata": {
        "id": "5YFx17_FBgqU"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorizer_test(review):\n",
        "    return tf.one_hot(vectorize_layer(review),depth=VOCAB_SIZE)\n",
        "\n",
        "test_dataset=test_data.map(vectorizer_test)\n",
        "model.predict(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0ZDrLH6B2MK",
        "outputId": "7bf8790b-23c4-45c9-b020-e17aad1bd5d5"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9695122],\n",
              "       [0.7549498]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Embedding"
      ],
      "metadata": {
        "id": "dXmjuWEZi58p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = tf.zeros([2000])\n",
        "layer = Embedding(2, 100)\n",
        "\n",
        "output = layer(input)\n",
        "print(output[0].shape)\n",
        "print(output[1].shape)\n",
        "print(output[2].shape)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNVwULECi76x",
        "outputId": "65a31f7d-f193-4c50-cd4e-5d0eaacb7520"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100,)\n",
            "(100,)\n",
            "(100,)\n",
            "(2000, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM"
      ],
      "metadata": {
        "id": "4vg0pl9ZcrqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = tf.zeros([8, 100,2000])\n",
        "layer = LSTM(4, activation = 'tanh', use_bias = True, return_sequences=True, return_state = True)\n",
        "\n",
        "output = layer(input)\n",
        "print(output[0].shape)\n",
        "print(output[1].shape)\n",
        "print(output[2].shape)\n",
        "print(len(output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yh3R7sVrcrMb",
        "outputId": "72d9e95d-7406-48dc-a349-e8ba8f091e62"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8, 100, 4)\n",
            "(8, 4)\n",
            "(8, 4)\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " input = tf.keras.layers.Input(shape = (SEQUENCE_LENGTH,VOCAB_SIZE))\n",
        " embedding_size = 256\n",
        "\n",
        " model = tf.keras.models.Sequential([\n",
        "                                     input,\n",
        "                                  \n",
        "                                     LSTM(4, activation = 'tanh', use_bias = True, return_sequences=True, name = \"layer1\"),\n",
        "                                     Dense(1, activation = \"relu\", name=\"layer2\"),\n",
        "                                     Reshape((SEQUENCE_LENGTH,), name = \"layer3\"),\n",
        "                                     Dense(1, activation = \"sigmoid\", name = \"layer4\")\n",
        " ])\n",
        " model.summary()\n",
        "\n",
        "LR = 1e-4\n",
        "EPOCH = 50\n",
        "\n",
        "model.compile(\n",
        "    loss = tf.keras.losses.BinaryCrossentropy(from_logits = True),\n",
        "    optimizer = tf.keras.optimizers.Adam(lr = LR,),\n",
        "    metrics = [\"accuracy\"],\n",
        ")\n",
        "checkpoint_filepath  = \"basic_rnn.hdf5\"\n",
        "\n",
        "#checkpoint_filepath=\"imdb/basic_rnn.hdf5\"\n",
        "callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "   filepath=checkpoint_filepath,### WHERE BEST WEIGHTS ARE STORED\n",
        "    save_weights_only=True,\n",
        "   monitor=\"loss\",\n",
        "   mode='min',\n",
        "    save_best_only=True)\n",
        "#Train model on dataset\n",
        "history=model.fit(train_dataset,validation_data=val_dataset,verbose=1,epochs=EPOCH,callbacks=[callback])#\n",
        "\n",
        "plt.plot(history.history[\"loss\"][:])\n",
        "plt.plot(history.history[\"val_loss\"][:])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','val'], loc = 'upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history[\"accuracy\"][:])\n",
        "plt.plot(history.history[\"val_accuracy\"][:])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','val'], loc = 'upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hfp-SiQpCFwI",
        "outputId": "9aead970-77a5-4ed6-d167-79891e54d413"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer1 (LSTM)               (None, 100, 4)            32080     \n",
            "                                                                 \n",
            " layer2 (Dense)              (None, 100, 1)            5         \n",
            "                                                                 \n",
            " layer3 (Reshape)            (None, 100)               0         \n",
            "                                                                 \n",
            " layer4 (Dense)              (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32,186\n",
            "Trainable params: 32,186\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 107s 135ms/step - loss: 0.6930 - accuracy: 0.5060 - val_loss: 0.6926 - val_accuracy: 0.5093\n",
            "Epoch 2/50\n",
            "782/782 [==============================] - 103s 132ms/step - loss: 0.6905 - accuracy: 0.5052 - val_loss: 0.6872 - val_accuracy: 0.5023\n",
            "Epoch 3/50\n",
            "782/782 [==============================] - 102s 130ms/step - loss: 0.6473 - accuracy: 0.5895 - val_loss: 0.6075 - val_accuracy: 0.7064\n",
            "Epoch 4/50\n",
            "782/782 [==============================] - 102s 130ms/step - loss: 0.5826 - accuracy: 0.7404 - val_loss: 0.5849 - val_accuracy: 0.7528\n",
            "Epoch 5/50\n",
            "782/782 [==============================] - 101s 129ms/step - loss: 0.5572 - accuracy: 0.7696 - val_loss: 0.5723 - val_accuracy: 0.7625\n",
            "Epoch 6/50\n",
            "782/782 [==============================] - 101s 129ms/step - loss: 0.5381 - accuracy: 0.7834 - val_loss: 0.5596 - val_accuracy: 0.7717\n",
            "Epoch 7/50\n",
            "782/782 [==============================] - 102s 131ms/step - loss: 0.5226 - accuracy: 0.7918 - val_loss: 0.5517 - val_accuracy: 0.7748\n",
            "Epoch 8/50\n",
            "782/782 [==============================] - 102s 130ms/step - loss: 0.5090 - accuracy: 0.7960 - val_loss: 0.5467 - val_accuracy: 0.7768\n",
            "Epoch 9/50\n",
            "782/782 [==============================] - 102s 130ms/step - loss: 0.4970 - accuracy: 0.8011 - val_loss: 0.5368 - val_accuracy: 0.7745\n",
            "Epoch 10/50\n",
            "782/782 [==============================] - 101s 129ms/step - loss: 0.4865 - accuracy: 0.8031 - val_loss: 0.5323 - val_accuracy: 0.7764\n",
            "Epoch 11/50\n",
            "782/782 [==============================] - 102s 130ms/step - loss: 0.4767 - accuracy: 0.8063 - val_loss: 0.5293 - val_accuracy: 0.7768\n",
            "Epoch 12/50\n",
            "782/782 [==============================] - 105s 134ms/step - loss: 0.4684 - accuracy: 0.8093 - val_loss: 0.5244 - val_accuracy: 0.7756\n",
            "Epoch 13/50\n",
            "211/782 [=======>......................] - ETA: 56s - loss: 0.4590 - accuracy: 0.8129"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-9ec7109e9c7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m    save_best_only=True)\n\u001b[1;32m     31\u001b[0m \u001b[0;31m#Train model on dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GRU"
      ],
      "metadata": {
        "id": "mmMeJNYmvfKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs=tf.keras.layers.Input(shape=(SEQUENCE_LENGTH,VOCAB_SIZE),)\n",
        "EMBEDDING_DIM=100\n",
        "embedding=tf.keras.layers.Embedding(VOCAB_SIZE,EMBEDDING_DIM)\n",
        "model=  tf.keras.models.Sequential([\n",
        "    inputs,\n",
        "    \n",
        "    tf.keras.layers.GRU(20,activation='tanh',use_bias=True,return_sequences=True),\n",
        "    tf.keras.layers.Dense(1,activation='relu'),\n",
        "    tf.keras.layers.Reshape((SEQUENCE_LENGTH,)),\n",
        "    tf.keras.layers.Dense(1,activation='sigmoid'),\n",
        "])\n",
        "model.summary()\n",
        "\n",
        "LR=5e-4\n",
        "EPOCH=15\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "    optimizer=tf.keras.optimizers.Adam(lr=LR,),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "checkpoint_filepath  = \"basic_rnn.hdf5\"\n",
        "\n",
        "callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor=\"val_loss\",\n",
        "    mode='min',\n",
        "    save_best_only=True)\n",
        "#Train model on dataset\n",
        "history = model.fit(train_dataset,validation_data=val_dataset,verbose=1,epochs=EPOCH,callbacks=[callback])\n",
        "plt.plot(history.history[\"loss\"][:])\n",
        "plt.plot(history.history[\"val_loss\"][:])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','val'], loc = 'upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history[\"accuracy\"][:])\n",
        "plt.plot(history.history[\"val_accuracy\"][:])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','val'], loc = 'upper left')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeSJl2auepIv",
        "outputId": "e7bb4147-5402-40e5-c271-4806e3e2c0f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_2 (GRU)                 (None, 100, 20)           121320    \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 100, 1)            21        \n",
            "                                                                 \n",
            " reshape_3 (Reshape)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121,442\n",
            "Trainable params: 121,442\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wa53vYg6n_YG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}